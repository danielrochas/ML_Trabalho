{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Dados com Métodos de Aprendizado de Máquina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução ao Aprendizado de Máquina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daniel Rocha da Silva, Laura Kubitschek Fiorindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link para repositório no GitHub: [Repositório no GitHub](https://github.com/danielrochas/ML_Trabalho/tree/main/Trabalho%202)\n",
    "\n",
    "Descrição do trabalho: [Descrição.pdf](https://github.com/danielrochas/ML_Trabalho/blob/main/Trabalho%202/Descrição.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importação e visualização do banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>%</th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweigh</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.579818</td>\n",
       "      <td>2.769459</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.430783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.994252</td>\n",
       "      <td>3.319626</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>2.691243</td>\n",
       "      <td>74</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.162519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.203973</td>\n",
       "      <td>3.282789</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.751416</td>\n",
       "      <td>3.432373</td>\n",
       "      <td>62</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.371564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>2.830268</td>\n",
       "      <td>3.876396</td>\n",
       "      <td>68</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>1</td>\n",
       "      <td>1.321756</td>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>4.385147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>3.821004</td>\n",
       "      <td>3.896909</td>\n",
       "      <td>44</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>1</td>\n",
       "      <td>2.169054</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>4.684443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>2.907447</td>\n",
       "      <td>3.396185</td>\n",
       "      <td>52</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>1</td>\n",
       "      <td>2.463853</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>5.143124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>2.882564</td>\n",
       "      <td>3.773910</td>\n",
       "      <td>68</td>\n",
       "      <td>1.558145</td>\n",
       "      <td>1</td>\n",
       "      <td>1.558145</td>\n",
       "      <td>7</td>\n",
       "      <td>80</td>\n",
       "      <td>5.477509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>3.471966</td>\n",
       "      <td>3.974998</td>\n",
       "      <td>68</td>\n",
       "      <td>0.438255</td>\n",
       "      <td>1</td>\n",
       "      <td>2.904165</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>5.582932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     %    lcavol    lweigh  age      lbph  svi       lcp  gleason  pgg45  \\\n",
       "0    1 -0.579818  2.769459   50 -1.386294    0 -1.386294        6      0   \n",
       "1    2 -0.994252  3.319626   58 -1.386294    0 -1.386294        6      0   \n",
       "2    3 -0.510826  2.691243   74 -1.386294    0 -1.386294        7     20   \n",
       "3    4 -1.203973  3.282789   58 -1.386294    0 -1.386294        6      0   \n",
       "4    5  0.751416  3.432373   62 -1.386294    0 -1.386294        6      0   \n",
       "..  ..       ...       ...  ...       ...  ...       ...      ...    ...   \n",
       "92  93  2.830268  3.876396   68 -1.386294    1  1.321756        7     60   \n",
       "93  94  3.821004  3.896909   44 -1.386294    1  2.169054        7     40   \n",
       "94  95  2.907447  3.396185   52 -1.386294    1  2.463853        7     10   \n",
       "95  96  2.882564  3.773910   68  1.558145    1  1.558145        7     80   \n",
       "96  97  3.471966  3.974998   68  0.438255    1  2.904165        7     20   \n",
       "\n",
       "        lpsa  \n",
       "0  -0.430783  \n",
       "1  -0.162519  \n",
       "2  -0.162519  \n",
       "3  -0.162519  \n",
       "4   0.371564  \n",
       "..       ...  \n",
       "92  4.385147  \n",
       "93  4.684443  \n",
       "94  5.143124  \n",
       "95  5.477509  \n",
       "96  5.582932  \n",
       "\n",
       "[97 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prostate_data = pd.read_csv('data/prostate.data', sep=\"\\t\")\n",
    "prostate_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualização da variável resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4.,  3.,  7., 17., 17., 26., 14.,  4.,  2.,  3.]),\n",
       " array([-0.4307829 ,  0.17058861,  0.77196012,  1.37333163,  1.97470314,\n",
       "         2.57607465,  3.17744616,  3.77881767,  4.38018918,  4.98156069,\n",
       "         5.5829322 ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.hist(prostate_data[\"lpsa\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir do histrograma da variável resposta *lpsa* é possível perceber que ela possui distribuição semelhante à Normal, uma vez que possui maior frequência nos valores centrais e menor frequência nas caudas a esquerda e a direita."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separação entre *features* e *target*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_prostate = prostate_data.drop(columns = {\"%\", \"lpsa\"})\n",
    "target_prostate = prostate_data[\"lpsa\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padronização das *features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features_prostate_scaled = scaler.fit_transform(features_prostate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separação do conjunto de treinamento (80%) e do conjunto de teste (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_prostate_train, features_prostate_test, target_prostate_train, target_prostate_test = \\\n",
    "    train_test_split(features_prostate_scaled, target_prostate, test_size = 0.2, random_state = 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajuste da Regressão Linear e cálculo de medidas de validação para o conjunto teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Conjunto Teste:  0.64\n",
      "EQM Conjunto Teste:  0.6\n",
      "\n",
      "\n",
      "Intercepto 2.47\n",
      "lcavol : 0.63\n",
      "lweigh : 0.27\n",
      "age : -0.12\n",
      "lbph : 0.05\n",
      "svi : 0.31\n",
      "lcp : -0.14\n",
      "gleason : 0.07\n",
      "pgg45 : 0.08\n"
     ]
    }
   ],
   "source": [
    "lr_prostate = LinearRegression()\n",
    "lr_prostate.fit(features_prostate_train, target_prostate_train);\n",
    "\n",
    "# Validação Conjunto Teste\n",
    "print(\"R^2 Conjunto Teste: \", round(lr_prostate.score(features_prostate_test, target_prostate_test),2))\n",
    "target_predicted = lr_prostate.predict(features_prostate_test)\n",
    "print(\"EQM Conjunto Teste: \",round(mean_squared_error(target_prostate_test, target_predicted),2))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Intercepto\", round(lr_prostate.intercept_,2))\n",
    "for i in range(len(lr_prostate.coef_)):\n",
    "    print(prostate_data.columns[i+1],\":\", round(lr_prostate.coef_[i],2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir dos valores apresentados acima, nota-se que as *features lcavol, lweigh, lbph, svi, gleason* e *pgg45*, por possuírem valores positivos dos coeficientes, contribuem de maneira positiva para o valor da variável resposta *lpsa*. Ou seja, o aumento do valor dessas variáveis provoca também um aumento no valor da resposta. Vale ressaltar que esse aumento provocado pelas variáveis *lbph, gleason* e *pgg45* é pequeno devido ao pequeno valor do coeficiente, em contrapartida, as variáveis *lcavol, lweigh* e*svi* possuem maior contribuição, por conta do maior valor de seus coeficientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por sua vez, as variáveis *age* e *lcp* possuem contribuição negativa sobre a variável resposta *lpsa*, pois, por terem o valor do coeficiente associado a elas negativo, um aumento no valores dessas covariáveis provoca uma redução no valor da resposta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo de regressão linear ajustado obteve o valor R-quadrado de 0.64, indicando que 64% da variabilidade da variável resposta está sendo explicada pelo modelo linear ajustado. Já o valor do erro quadrático médio, que deve sempre ser minimizado, para o modelo construído, foi obtido o valor de 0.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>x43</th>\n",
       "      <th>x44</th>\n",
       "      <th>x45</th>\n",
       "      <th>x46</th>\n",
       "      <th>x47</th>\n",
       "      <th>x48</th>\n",
       "      <th>x49</th>\n",
       "      <th>x50</th>\n",
       "      <th>x51</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.110226</td>\n",
       "      <td>0</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.223008</td>\n",
       "      <td>0</td>\n",
       "      <td>0.129464</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0</td>\n",
       "      <td>0.169210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.530075</td>\n",
       "      <td>0</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0</td>\n",
       "      <td>0.289757</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.139098</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.233083</td>\n",
       "      <td>0</td>\n",
       "      <td>0.528214</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.260602</td>\n",
       "      <td>0</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029821</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0</td>\n",
       "      <td>0.155805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033835</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111607</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.169210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     x1  x2  x3        x4  x5        x6  x7  x8  x9  x10  ...  x43       x44  \\\n",
       "0     1   0   0  0.000000   1  0.178571   0   1   0    0  ...    0  0.000000   \n",
       "1     0   1   0  0.110226   0  0.178571   0   1   0    0  ...    0  0.000000   \n",
       "2     1   0   0  0.223008   0  0.129464   1   0   0    0  ...    0  0.000000   \n",
       "3     1   0   0  0.078947   0  0.062500   0   1   0    0  ...    0  0.000000   \n",
       "4     0   1   0  0.530075   0  0.053571   1   0   0    0  ...    0  0.000000   \n",
       "..   ..  ..  ..       ...  ..       ...  ..  ..  ..  ...  ...  ...       ...   \n",
       "685   1   0   0  0.139098   0  0.026786   1   0   0    0  ...    0  0.000000   \n",
       "686   1   0   0  0.233083   0  0.528214   1   0   0    0  ...    1  0.074627   \n",
       "687   1   0   0  0.260602   0  0.053571   0   1   0    0  ...    0  0.000000   \n",
       "688   1   0   0  0.357143   0  0.029821   1   0   0    0  ...    0  0.000000   \n",
       "689   1   0   0  0.033835   0  0.111607   1   0   0    0  ...    1  0.014925   \n",
       "\n",
       "     x45  x46  x47  x48    x49  x50       x51  y  \n",
       "0      0    1    0    0  0.000    0  0.000000  1  \n",
       "1      0    1    0    0  0.000    0  0.000000  1  \n",
       "2      1    1    0    0  0.050    0  0.000000  1  \n",
       "3      1    1    0    0  0.056    0  0.169210  1  \n",
       "4      1    1    0    0  0.050    0  0.289757  1  \n",
       "..   ...  ...  ...  ...    ...  ...       ... ..  \n",
       "685    1    0    0    1  0.160    0  0.000000  1  \n",
       "686    1    1    0    0  0.084    0  0.000000  0  \n",
       "687    0    0    0    1  0.080    0  0.000000  1  \n",
       "688    0    1    0    0  0.060    0  0.155805  1  \n",
       "689    0    1    0    0  0.000    0  0.169210  1  \n",
       "\n",
       "[690 rows x 52 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_data = pd.read_csv('data/card.csv', sep=\",\")\n",
    "card_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualização da variável resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'Distribuição dos dados da variável resposta (y)')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "unique, counts = np.unique(card_data[\"y\"], return_counts = True)\n",
    "unique = ''.join(str(e) for e in unique)\n",
    "plot_data = dict(zip(unique, counts))\n",
    "\n",
    "names = list(plot_data.keys())\n",
    "values = list(plot_data.values())\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize = (5, 6))\n",
    "axs.bar(names, values)\n",
    "fig.suptitle('Distribuição dos dados da variável resposta (y)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por meio do gráfico acima, é possível notar que a variável resposta, que é categórica, possui apenas 2 níveis, sendo eles 0 ou 1. Além disso, as duas categorias possuem frequências próximas, indicando que os dados estão, de certa forma, balanceados de acordo com a variável resposta. Nesse problema serão ajustados 3 modelos diferentes para avaliação das métricas, são eles: KNN (k=5), Naive Bayes e Regressão Logística."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separação entre *features* e *target*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_card = card_data.drop(columns = {\"y\"})\n",
    "target_card = card_data[\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padronização das *features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features_card_scaled = scaler.fit_transform(features_card)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando o método 5-vizinhos mais próximos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados normalizados:\n",
      "\n",
      "\n",
      "Acurácia:  [0.79710145 0.79710145 0.76811594 0.73913043 0.82608696 0.86956522\n",
      " 0.79710145 0.82608696 0.79710145 0.7826087 ] Média:  0.8\n",
      "\n",
      "\n",
      "Recall:  [0.94871795 0.84615385 0.8974359  0.78947368 0.86842105 0.86842105\n",
      " 0.86842105 0.89473684 0.84210526 0.84210526] Média:  0.8665991902834008\n",
      "\n",
      "\n",
      "Precison:  [0.75510204 0.80487805 0.74468085 0.75       0.825      0.89189189\n",
      " 0.78571429 0.80952381 0.8        0.7804878 ] Média:  0.794727873266868\n",
      "\n",
      "\n",
      "f1:  [0.84090909 0.825      0.81395349 0.76923077 0.84615385 0.88\n",
      " 0.825      0.85       0.82051282 0.81012658] Média:  0.8280886597457101\n",
      "\n",
      "\n",
      "Dados originais:\n",
      "\n",
      "\n",
      "Acurácia:  [0.76811594 0.82608696 0.8115942  0.82608696 0.92753623 0.91304348\n",
      " 0.85507246 0.85507246 0.7826087  0.85507246] Média:  0.8420289855072463\n",
      "\n",
      "\n",
      "Recall:  [0.84615385 0.84615385 0.84615385 0.84210526 0.92105263 0.86842105\n",
      " 0.92105263 0.94736842 0.78947368 0.89473684] Média:  0.8722672064777328\n",
      "\n",
      "\n",
      "Precison:  [0.76744186 0.84615385 0.825      0.84210526 0.94594595 0.97058824\n",
      " 0.83333333 0.81818182 0.81081081 0.85      ] Média:  0.8509561113342883\n",
      "\n",
      "\n",
      "f1:  [0.80487805 0.84615385 0.83544304 0.84210526 0.93333333 0.91666667\n",
      " 0.875      0.87804878 0.8        0.87179487] Média:  0.860342384834959\n"
     ]
    }
   ],
   "source": [
    "neigh_card = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh_card.fit(features_card_scaled, target_card);\n",
    "\n",
    "# Validação cruzada com método 10-fold\n",
    "print(\"Dados normalizados:\")\n",
    "score = cross_val_score(neigh_card, features_card_scaled, target_card, cv = 10, scoring = \"accuracy\")\n",
    "print(\"\\n\")\n",
    "print(\"Acurácia: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_card, features_card_scaled, target_card, cv = 10, scoring = \"recall\")\n",
    "print(\"\\n\")\n",
    "print(\"Recall: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_card, features_card_scaled, target_card, cv = 10, scoring = \"precision\")\n",
    "print(\"\\n\")\n",
    "print(\"Precison: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_card, features_card_scaled, target_card, cv = 10, scoring = \"f1\")\n",
    "print(\"\\n\")\n",
    "print(\"f1: \", score, \"Média: \", np.mean(score))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Dados originais:\")\n",
    "score = cross_val_score(neigh_card, features_card, target_card, cv = 10, scoring = \"accuracy\")\n",
    "print(\"\\n\")\n",
    "print(\"Acurácia: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_card, features_card, target_card, cv = 10, scoring = \"recall\")\n",
    "print(\"\\n\")\n",
    "print(\"Recall: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_card, features_card, target_card, cv = 10, scoring = \"precision\")\n",
    "print(\"\\n\")\n",
    "print(\"Precison: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_card, features_card, target_card, cv = 10, scoring = \"f1\")\n",
    "print(\"\\n\")\n",
    "print(\"f1: \", score, \"Média: \", np.mean(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao ajustar o modelo de 5 vizinhos mais próximos nos dados padronizados e nos dados originais, observou-se melhor resultado no modelo em que foi utilizado os dados originais. Considerando o modelo com os dados originais, foram obtidas as seguintes métricas de avaliação do modelo:\n",
    "\n",
    "* acurácia média de 0.84;\n",
    "* sensibilidade média de 0.87\n",
    "* precisão média de 0.85\n",
    "* f1 médio de 0.86"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando o método Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia:  [0.66666667 0.73913043 0.69565217 0.66666667 0.65217391 0.69565217\n",
      " 0.73913043 0.68115942 0.68115942 0.65217391] Média:  0.6869565217391305\n",
      "Recall:  [0.97435897 1.         1.         0.86842105 0.97368421 0.94736842\n",
      " 1.         0.89473684 0.94736842 0.97368421] Média:  0.9579622132253711\n",
      "Precison:  [0.63333333 0.68421053 0.65       0.64705882 0.61666667 0.65454545\n",
      " 0.67857143 0.65384615 0.64285714 0.61666667] Média:  0.6477756196332048\n",
      "f1:  [0.76767677 0.8125     0.78787879 0.74157303 0.75510204 0.77419355\n",
      " 0.80851064 0.75555556 0.76595745 0.75510204] Média:  0.7724049859945109\n"
     ]
    }
   ],
   "source": [
    "gaussian_nb_card = GaussianNB()\n",
    "gaussian_nb_card.fit(features_card, target_card);\n",
    "\n",
    "# Validação cruzada com método 10-fold\n",
    "score = cross_val_score(gaussian_nb_card, features_card, target_card, cv = 10, scoring = \"accuracy\")\n",
    "print(\"Acurácia: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(gaussian_nb_card, features_card, target_card, cv = 10, scoring = \"recall\")\n",
    "print(\"Recall: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(gaussian_nb_card, features_card, target_card, cv = 10, scoring = \"precision\")\n",
    "print(\"Precison: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(gaussian_nb_card, features_card, target_card, cv = 10, scoring = \"f1\")\n",
    "print(\"f1: \", score, \"Média: \", np.mean(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao ajustar o modelo naive bayes nos dados originais, foram obtidas as seguintes métricas de avaliação do modelo:\n",
    "\n",
    "* acurácia média de 0.69;\n",
    "* sensibilidade média de 0.96\n",
    "* precisão média de 0.64 \n",
    "* f1 médio de 0.77"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando os resultados do modelo KNN e Naive Bayes, observou-se que o primeiro possui métricas de avaliação melhores, por possuir valores maiores dessas medidas, exceto quando se trata da sensibilidade. Nesse caso, como o modelo naive bayes possui alta sensibilidade ele é bom para identificar instâncias positiva quanto a concessão quando ela é realmente positiva. No entanto, nesse caso a precisão do modelo não é tão boa, indicando que ao classificar uma instância como positiva existe uma proporção considerável delas que na realidade é negativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando o método de Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia:  [0.76811594 0.86956522 0.85507246 0.79710145 0.86956522 0.91304348\n",
      " 0.88405797 0.86956522 0.85507246 0.88405797] Média:  0.8565217391304347\n",
      "Recall:  [0.79487179 0.87179487 0.8974359  0.73684211 0.81578947 0.86842105\n",
      " 0.86842105 0.92105263 0.78947368 0.89473684] Média:  0.8458839406207828\n",
      "Precison:  [0.79487179 0.89473684 0.85365854 0.875      0.93939394 0.97058824\n",
      " 0.91666667 0.85365854 0.9375     0.89473684] Média:  0.8930811393607778\n",
      "f1:  [0.79487179 0.88311688 0.875      0.8        0.87323944 0.91666667\n",
      " 0.89189189 0.88607595 0.85714286 0.89473684] Média:  0.8672742321782165\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_card = LogisticRegression()\n",
    "logistic_regression_card.fit(features_card_scaled,target_card)\n",
    "\n",
    "score = cross_val_score(logistic_regression_card, features_card_scaled, target_card, cv = 10, scoring = \"accuracy\")\n",
    "print(\"Acurácia: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(logistic_regression_card, features_card_scaled, target_card, cv = 10, scoring = \"recall\")\n",
    "print(\"Recall: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(logistic_regression_card, features_card_scaled, target_card, cv = 10, scoring = \"precision\")\n",
    "print(\"Precison: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(logistic_regression_card, features_card_scaled, target_card, cv = 10, scoring = \"f1\")\n",
    "print(\"f1: \", score, \"Média: \", np.mean(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao ajustar o modelo de regressão logística nos dados originais, foram obtidas seguintes métricas de avaliação do modelo:\n",
    "\n",
    "* acurácia média de 0.86;\n",
    "* sensibilidade média de 0.85\n",
    "* precisão média de 0.90\n",
    "* f1 médio de 0.87"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando o modelo logístico com os demais, ele possui sensibilidade inferior aos modelos KNN e Naive Bayes, no entanto, para as demais métricas, obteve medidas mais elevadas se comparadas com os demais modelos. Nesse caso, cabe ao banco avaliar qual métrica deve ser maximizada em um modelo para classificação da concessão de crédito. Uma alta sensibilidade indica que o modelo prevê bem instâncias como positiva quanto a concessão quando ela é realmente positiva. No entanto, também é interessante que a precisão do modelo seja alta, para assim evitar prejuízos ao aumentar a proporção de observações verdadeiramente positivas quando elas foram classificadas positivas. Nesse sentido, o modelo de regressão logística parece ser ideal, tendo valores altos para todas métricas de avaliação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importação e visualização do banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inst.Name</th>\n",
       "      <th>Private</th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top10perc</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F.Undergrad</th>\n",
       "      <th>P.Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room.Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S.F.Ratio</th>\n",
       "      <th>perc.alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad.Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilene Christian University</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1660</td>\n",
       "      <td>1232</td>\n",
       "      <td>721</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>2885</td>\n",
       "      <td>537</td>\n",
       "      <td>7440</td>\n",
       "      <td>3300</td>\n",
       "      <td>450</td>\n",
       "      <td>2200</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>18.1</td>\n",
       "      <td>12</td>\n",
       "      <td>7041</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelphi University</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2186</td>\n",
       "      <td>1924</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>2683</td>\n",
       "      <td>1227</td>\n",
       "      <td>12280</td>\n",
       "      <td>6450</td>\n",
       "      <td>750</td>\n",
       "      <td>1500</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16</td>\n",
       "      <td>10527</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adrian College</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1428</td>\n",
       "      <td>1097</td>\n",
       "      <td>336</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>1036</td>\n",
       "      <td>99</td>\n",
       "      <td>11250</td>\n",
       "      <td>3750</td>\n",
       "      <td>400</td>\n",
       "      <td>1165</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>12.9</td>\n",
       "      <td>30</td>\n",
       "      <td>8735</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agnes Scott College</td>\n",
       "      <td>Yes</td>\n",
       "      <td>417</td>\n",
       "      <td>349</td>\n",
       "      <td>137</td>\n",
       "      <td>60</td>\n",
       "      <td>89</td>\n",
       "      <td>510</td>\n",
       "      <td>63</td>\n",
       "      <td>12960</td>\n",
       "      <td>5450</td>\n",
       "      <td>450</td>\n",
       "      <td>875</td>\n",
       "      <td>92</td>\n",
       "      <td>97</td>\n",
       "      <td>7.7</td>\n",
       "      <td>37</td>\n",
       "      <td>19016</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alaska Pacific University</td>\n",
       "      <td>Yes</td>\n",
       "      <td>193</td>\n",
       "      <td>146</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>249</td>\n",
       "      <td>869</td>\n",
       "      <td>7560</td>\n",
       "      <td>4120</td>\n",
       "      <td>800</td>\n",
       "      <td>1500</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2</td>\n",
       "      <td>10922</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>Worcester State College</td>\n",
       "      <td>No</td>\n",
       "      <td>2197</td>\n",
       "      <td>1515</td>\n",
       "      <td>543</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>3089</td>\n",
       "      <td>2029</td>\n",
       "      <td>6797</td>\n",
       "      <td>3900</td>\n",
       "      <td>500</td>\n",
       "      <td>1200</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14</td>\n",
       "      <td>4469</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>Xavier University</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1959</td>\n",
       "      <td>1805</td>\n",
       "      <td>695</td>\n",
       "      <td>24</td>\n",
       "      <td>47</td>\n",
       "      <td>2849</td>\n",
       "      <td>1107</td>\n",
       "      <td>11520</td>\n",
       "      <td>4960</td>\n",
       "      <td>600</td>\n",
       "      <td>1250</td>\n",
       "      <td>73</td>\n",
       "      <td>75</td>\n",
       "      <td>13.3</td>\n",
       "      <td>31</td>\n",
       "      <td>9189</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>Xavier University of Louisiana</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2097</td>\n",
       "      <td>1915</td>\n",
       "      <td>695</td>\n",
       "      <td>34</td>\n",
       "      <td>61</td>\n",
       "      <td>2793</td>\n",
       "      <td>166</td>\n",
       "      <td>6900</td>\n",
       "      <td>4200</td>\n",
       "      <td>617</td>\n",
       "      <td>781</td>\n",
       "      <td>67</td>\n",
       "      <td>75</td>\n",
       "      <td>14.4</td>\n",
       "      <td>20</td>\n",
       "      <td>8323</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>Yale University</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10705</td>\n",
       "      <td>2453</td>\n",
       "      <td>1317</td>\n",
       "      <td>95</td>\n",
       "      <td>99</td>\n",
       "      <td>5217</td>\n",
       "      <td>83</td>\n",
       "      <td>19840</td>\n",
       "      <td>6510</td>\n",
       "      <td>630</td>\n",
       "      <td>2115</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>5.8</td>\n",
       "      <td>49</td>\n",
       "      <td>40386</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>York College of Pennsylvania</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2989</td>\n",
       "      <td>1855</td>\n",
       "      <td>691</td>\n",
       "      <td>28</td>\n",
       "      <td>63</td>\n",
       "      <td>2988</td>\n",
       "      <td>1726</td>\n",
       "      <td>4990</td>\n",
       "      <td>3560</td>\n",
       "      <td>500</td>\n",
       "      <td>1250</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>18.1</td>\n",
       "      <td>28</td>\n",
       "      <td>4509</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>777 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Inst.Name Private   Apps  Accept  Enroll  Top10perc  \\\n",
       "0      Abilene Christian University     Yes   1660    1232     721         23   \n",
       "1                Adelphi University     Yes   2186    1924     512         16   \n",
       "2                    Adrian College     Yes   1428    1097     336         22   \n",
       "3               Agnes Scott College     Yes    417     349     137         60   \n",
       "4         Alaska Pacific University     Yes    193     146      55         16   \n",
       "..                              ...     ...    ...     ...     ...        ...   \n",
       "772         Worcester State College      No   2197    1515     543          4   \n",
       "773               Xavier University     Yes   1959    1805     695         24   \n",
       "774  Xavier University of Louisiana     Yes   2097    1915     695         34   \n",
       "775                 Yale University     Yes  10705    2453    1317         95   \n",
       "776    York College of Pennsylvania     Yes   2989    1855     691         28   \n",
       "\n",
       "     Top25perc  F.Undergrad  P.Undergrad  Outstate  Room.Board  Books  \\\n",
       "0           52         2885          537      7440        3300    450   \n",
       "1           29         2683         1227     12280        6450    750   \n",
       "2           50         1036           99     11250        3750    400   \n",
       "3           89          510           63     12960        5450    450   \n",
       "4           44          249          869      7560        4120    800   \n",
       "..         ...          ...          ...       ...         ...    ...   \n",
       "772         26         3089         2029      6797        3900    500   \n",
       "773         47         2849         1107     11520        4960    600   \n",
       "774         61         2793          166      6900        4200    617   \n",
       "775         99         5217           83     19840        6510    630   \n",
       "776         63         2988         1726      4990        3560    500   \n",
       "\n",
       "     Personal  PhD  Terminal  S.F.Ratio  perc.alumni  Expend  Grad.Rate  \n",
       "0        2200   70        78       18.1           12    7041         60  \n",
       "1        1500   29        30       12.2           16   10527         56  \n",
       "2        1165   53        66       12.9           30    8735         54  \n",
       "3         875   92        97        7.7           37   19016         59  \n",
       "4        1500   76        72       11.9            2   10922         15  \n",
       "..        ...  ...       ...        ...          ...     ...        ...  \n",
       "772      1200   60        60       21.0           14    4469         40  \n",
       "773      1250   73        75       13.3           31    9189         83  \n",
       "774       781   67        75       14.4           20    8323         49  \n",
       "775      2115   96        96        5.8           49   40386         99  \n",
       "776      1250   75        75       18.1           28    4509         99  \n",
       "\n",
       "[777 rows x 19 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college_data = pd.read_csv(\"data/College.csv\")\n",
    "college_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi feita a troca da variável *Top10perc* pela variável *Elite*, sendo esta uma variável que assume o valor 0 para valores da variável *Top10perc* no intervalo (-1, 50] e 1 para valores no intervalo (50, 101]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "college_data[\"Elite\"] = pd.cut(college_data[\"Top10perc\"], bins = (-1,50,101), labels = False)\n",
    "college_data = college_data.drop(columns = {\"Top10perc\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi feita a troca da variável Private para valores inteiros (Yes = 1; No = 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "college_data[\"Private\"] = np.where(college_data[\"Private\"] == 'Yes', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualização da variável resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'Distribuição dos dados da variável resposta (Elite)')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "unique, counts = np.unique(college_data[\"Elite\"], return_counts = True)\n",
    "unique = ''.join(str(e) for e in unique)\n",
    "plot_data = dict(zip(unique, counts))\n",
    "\n",
    "names = list(plot_data.keys())\n",
    "values = list(plot_data.values())\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize = (5, 6))\n",
    "axs.bar(names, values)\n",
    "fig.suptitle('Distribuição dos dados da variável resposta (Elite)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o gráfico acima podemos perceber como a variável resposta apresenta classes (0, 1) com frequência nos dados desbalanceada. Isso deve ser observado nos modelos feitos a seguir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separação entre *features* e *target*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_college = college_data.drop(columns = {\"Inst.Name\", \"Elite\"})\n",
    "target_college = college_data[\"Elite\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi feita a padronização das *features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features_college_scaled = scaler.fit_transform(features_college)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos o método K-vizinhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados normalizados:\n",
      "Acurácia:  [0.93589744 0.96153846 0.97435897 0.94871795 0.94871795 0.93589744\n",
      " 0.91025641 0.8961039  0.97402597 0.93506494] Média:  0.942057942057942\n",
      "Recall:  [0.75       0.625      0.75       0.5        0.5        0.5\n",
      " 0.125      0.14285714 0.71428571 0.625     ] Média:  0.5232142857142856\n",
      "Precison:  [0.66666667 1.         1.         1.         1.         0.8\n",
      " 1.         0.33333333 1.         0.71428571] Média:  0.8514285714285714\n",
      "f1:  [0.70588235 0.76923077 0.85714286 0.66666667 0.66666667 0.61538462\n",
      " 0.22222222 0.2        0.83333333 0.66666667] Média:  0.6203196150254974\n",
      "\n",
      "\n",
      "Dados originais:\n",
      "Acurácia:  [0.91025641 0.93589744 0.96153846 0.93589744 0.94871795 0.92307692\n",
      " 0.8974359  0.90909091 0.92207792 0.94805195] Média:  0.9292041292041292\n",
      "Recall:  [0.5        0.375      0.625      0.5        0.5        0.375\n",
      " 0.125      0.14285714 0.57142857 0.625     ] Média:  0.43392857142857144\n",
      "Precison:  [0.57142857 1.         1.         0.8        1.         0.75\n",
      " 0.5        0.5        0.57142857 0.83333333] Média:  0.7526190476190476\n",
      "f1:  [0.53333333 0.54545455 0.76923077 0.61538462 0.66666667 0.5\n",
      " 0.2        0.22222222 0.57142857 0.71428571] Média:  0.5338006438006437\n"
     ]
    }
   ],
   "source": [
    "neigh_college = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh_college.fit(features_college_scaled, target_college);\n",
    "\n",
    "# Validação cruzada com método 10-fold\n",
    "print(\"Dados normalizados:\")\n",
    "score = cross_val_score(neigh_college, features_college_scaled, target_college, cv = 10, scoring = \"accuracy\")\n",
    "print(\"Acurácia: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_college, features_college_scaled, target_college, cv = 10, scoring = \"recall\")\n",
    "print(\"Recall: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_college, features_college_scaled, target_college, cv = 10, scoring = \"precision\")\n",
    "print(\"Precison: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_college, features_college_scaled, target_college, cv = 10, scoring = \"f1\")\n",
    "print(\"f1: \", score, \"Média: \", np.mean(score))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Dados originais:\")\n",
    "score = cross_val_score(neigh_college, features_college, target_college, cv = 10, scoring = \"accuracy\")\n",
    "print(\"Acurácia: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_college, features_college, target_college, cv = 10, scoring = \"recall\")\n",
    "print(\"Recall: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_college, features_college, target_college, cv = 10, scoring = \"precision\")\n",
    "print(\"Precison: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_college, features_college, target_college, cv = 10, scoring = \"f1\")\n",
    "print(\"f1: \", score, \"Média: \", np.mean(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver com os resultados acima conseguimos resultados melhores com a normalização das *features*. \n",
    "\n",
    "Podemos perceber também que a medida de acurácia pode ser enganosa já que, neste caso, temos classes bem desbalanceadas. Por isso as medidas *recall*, *precision* e *f1* são mais interessantes para a situação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia:  [0.92307692 0.97435897 0.94871795 0.91025641 0.97435897 0.94871795\n",
      " 0.93589744 0.88311688 0.94805195 0.90909091] Média:  0.9355644355644355\n",
      "Recall:  [0.875      1.         0.875      0.75       0.75       1.\n",
      " 0.625      0.42857143 0.85714286 1.        ] Média:  0.8160714285714284\n",
      "Precison:  [0.58333333 0.8        0.7        0.54545455 1.         0.66666667\n",
      " 0.71428571 0.375      0.66666667 0.53333333] Média:  0.658474025974026\n",
      "f1:  [0.7        0.88888889 0.77777778 0.63157895 0.85714286 0.8\n",
      " 0.66666667 0.4        0.75       0.69565217] Média:  0.7167707311757655\n"
     ]
    }
   ],
   "source": [
    "gaussian_nb_college = GaussianNB()\n",
    "gaussian_nb_college.fit(features_college, target_college);\n",
    "\n",
    "# Validação cruzada com método 10-fold\n",
    "score = cross_val_score(gaussian_nb_college, features_college, target_college, cv = 10, scoring = \"accuracy\")\n",
    "print(\"Acurácia: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(gaussian_nb_college, features_college, target_college, cv = 10, scoring = \"recall\")\n",
    "print(\"Recall: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(gaussian_nb_college, features_college, target_college, cv = 10, scoring = \"precision\")\n",
    "print(\"Precison: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(gaussian_nb_college, features_college, target_college, cv = 10, scoring = \"f1\")\n",
    "print(\"f1: \", score, \"Média: \", np.mean(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o *Naive Bayes Gaussiano* não precisamos normalizar as *features*.\n",
    "\n",
    "Podemos perceber com as métricas apresentadas acima que os resultados obtidos com o método de *Naive Bayes* foram melhores pela métrica *recall*. Esta métrica representa a proporção de classificações 1 corretamente identificadas pelo modelo dentre todas as verdadeiras classificações 1 nos dados, essa medida, em geral é muito importante e um incremento nela é algo significativo. Já na métrica *precision* tivemos uma piora em relação ao modelo k-vizinhos. Esta métrica representa a proporção de classificações 1 feitas pelo modelo que realmente são classificações 1 nos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
       "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273   \n",
       "\n",
       "     ptratio   black  lstat  medv  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90   5.33  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99   9.67  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_data = pd.read_csv(\"data/Boston.csv\", sep = \";\", decimal = \",\")\n",
    "boston_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualização da variável resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 21.,  55.,  82., 154.,  84.,  41.,  30.,   8.,  10.,  21.]),\n",
       " array([ 5. ,  9.5, 14. , 18.5, 23. , 27.5, 32. , 36.5, 41. , 45.5, 50. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.hist(boston_data[\"medv\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o gráfico acima podemos perceber como a variável resposta apresenta um comportamento semelhante a uma distribuição normal. Ela apresenta um intervalo central mais frequente e tem a frequência reduzida nas caudas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separação entre features e target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_boston = boston_data.drop(columns = {\"medv\"})\n",
    "target_boston = boston_data[\"medv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi feita a padronização das features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features_boston_scaled = scaler.fit_transform(features_boston)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separação do conjunto de treinamento (80%) e do conjunto de teste (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_boston_train, features_boston_test, target_boston_train, target_boston_test = \\\n",
    "    train_test_split(features_boston_scaled, target_boston, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos o método de Regressão Linear e calculamos uma medida de validação no conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2:  0.6687594935356322\n",
      "\n",
      "\n",
      "Intercepto 22.485268239316902\n",
      "crim -0.9714942298153109\n",
      "zn 0.7015556186825168\n",
      "indus 0.27675211756097745\n",
      "chas 0.7065315219738251\n",
      "nox -1.9914304346295502\n",
      "rm 3.115718363958981\n",
      "age -0.17706020680903325\n",
      "dis -3.045770645410489\n",
      "rad 2.282784712788725\n",
      "tax -1.792604675752152\n",
      "ptratio -1.9799535094590697\n",
      "black 1.126498635557213\n",
      "lstat -3.628149374371363\n"
     ]
    }
   ],
   "source": [
    "lr_boston = LinearRegression()\n",
    "lr_boston.fit(features_boston_train, target_boston_train);\n",
    "\n",
    "# Validação\n",
    "print(\"R^2: \", lr_boston.score(features_boston_test, target_boston_test))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Intercepto\", lr_boston.intercept_)\n",
    "for i in range(len(lr_boston.coef_)):\n",
    "    print(boston_data.columns[i], lr_boston.coef_[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos perceber pelos coeficientes apresentados acima que as *features* *crim*, *nox*, *age*, *dis*, *tax*, *ptratio* e *lstat* fornecem uma contribuição negativa para o *target*. Dentre essas *features* podemos destacar *dis* e *lstat* como aquelas que mais influenciam negativamente no preço e este comportamento é aquele esperado para elas.\n",
    "\n",
    "As *features* *zn*, *indus*, *chas*, *rm*, *rad* e *black* fornecem uma contribuição positiva para o *target*. Dentre essas *features* podemos destacar *rm* como aquela que mais influencia positivamente no preço e este comportamento é aquele esperado para ela, já que esta representa a quantidade média de quartos das residências daquele local."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
