{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Dados com Métodos de Aprendizado de Máquina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução ao Aprendizado de Máquina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daniel Rocha da Silva, Laura Kubitschek Fiorindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link para repositório no GitHub: [Repositório no GitHub](https://github.com/danielrochas/ML_Trabalho/tree/main/Trabalho%202)\n",
    "\n",
    "Descrição do trabalho: [Descrição.pdf](https://github.com/danielrochas/ML_Trabalho/blob/main/Trabalho%202/Descrição.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Laura\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:35: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\Laura\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:597: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Users\\Laura\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:836: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Users\\Laura\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "C:\\Users\\Laura\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1074: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=1, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\Laura\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1306: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=1, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\Laura\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1442: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "C:\\Users\\Laura\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:152: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  precompute=False, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\Laura\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:318: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, random_state=None,\n",
      "C:\\Users\\Laura\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:575: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=4 * np.finfo(np.float).eps, n_jobs=1,\n",
      "C:\\Users\\Laura\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "C:\\Users\\Laura\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:34: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  from ._gradient_boosting import predict_stages\n",
      "C:\\Users\\Laura\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:34: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  from ._gradient_boosting import predict_stages\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import explained_variance_score,mean_absolute_error,r2_score,mean_squared_error\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importação e visualização do banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>%</th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweigh</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.579818</td>\n",
       "      <td>2.769459</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.430783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.994252</td>\n",
       "      <td>3.319626</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>2.691243</td>\n",
       "      <td>74</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.162519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.203973</td>\n",
       "      <td>3.282789</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.751416</td>\n",
       "      <td>3.432373</td>\n",
       "      <td>62</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.371564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>2.830268</td>\n",
       "      <td>3.876396</td>\n",
       "      <td>68</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>1</td>\n",
       "      <td>1.321756</td>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>4.385147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>3.821004</td>\n",
       "      <td>3.896909</td>\n",
       "      <td>44</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>1</td>\n",
       "      <td>2.169054</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>4.684443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>2.907447</td>\n",
       "      <td>3.396185</td>\n",
       "      <td>52</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>1</td>\n",
       "      <td>2.463853</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>5.143124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>2.882564</td>\n",
       "      <td>3.773910</td>\n",
       "      <td>68</td>\n",
       "      <td>1.558145</td>\n",
       "      <td>1</td>\n",
       "      <td>1.558145</td>\n",
       "      <td>7</td>\n",
       "      <td>80</td>\n",
       "      <td>5.477509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>3.471966</td>\n",
       "      <td>3.974998</td>\n",
       "      <td>68</td>\n",
       "      <td>0.438255</td>\n",
       "      <td>1</td>\n",
       "      <td>2.904165</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>5.582932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     %    lcavol    lweigh  age      lbph  svi       lcp  gleason  pgg45  \\\n",
       "0    1 -0.579818  2.769459   50 -1.386294    0 -1.386294        6      0   \n",
       "1    2 -0.994252  3.319626   58 -1.386294    0 -1.386294        6      0   \n",
       "2    3 -0.510826  2.691243   74 -1.386294    0 -1.386294        7     20   \n",
       "3    4 -1.203973  3.282789   58 -1.386294    0 -1.386294        6      0   \n",
       "4    5  0.751416  3.432373   62 -1.386294    0 -1.386294        6      0   \n",
       "..  ..       ...       ...  ...       ...  ...       ...      ...    ...   \n",
       "92  93  2.830268  3.876396   68 -1.386294    1  1.321756        7     60   \n",
       "93  94  3.821004  3.896909   44 -1.386294    1  2.169054        7     40   \n",
       "94  95  2.907447  3.396185   52 -1.386294    1  2.463853        7     10   \n",
       "95  96  2.882564  3.773910   68  1.558145    1  1.558145        7     80   \n",
       "96  97  3.471966  3.974998   68  0.438255    1  2.904165        7     20   \n",
       "\n",
       "        lpsa  \n",
       "0  -0.430783  \n",
       "1  -0.162519  \n",
       "2  -0.162519  \n",
       "3  -0.162519  \n",
       "4   0.371564  \n",
       "..       ...  \n",
       "92  4.385147  \n",
       "93  4.684443  \n",
       "94  5.143124  \n",
       "95  5.477509  \n",
       "96  5.582932  \n",
       "\n",
       "[97 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prostate_data = pd.read_csv('data/prostate.data', sep=\"\\t\")\n",
    "prostate_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualização da variável resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4.,  3.,  7., 17., 17., 26., 14.,  4.,  2.,  3.]),\n",
       " array([-0.4307829 ,  0.17058861,  0.77196012,  1.37333163,  1.97470314,\n",
       "         2.57607465,  3.17744616,  3.77881767,  4.38018918,  4.98156069,\n",
       "         5.5829322 ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.hist(prostate_data[\"lpsa\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir do histrograma da variável resposta *lpsa* é possível perceber que ela possui distribuição semelhante à Normal, uma vez que possui maior frequência nos valores centrais e menor frequência nas caudas a esquerda e a direita."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separação entre *features* e *target*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_prostate = prostate_data.drop(columns = {\"%\", \"lpsa\"})\n",
    "target_prostate = prostate_data[\"lpsa\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padronização das *features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features_prostate_scaled = scaler.fit_transform(features_prostate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separação do conjunto de treinamento (80%) e do conjunto de teste (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_prostate_train, features_prostate_test, target_prostate_train, target_prostate_test = \\\n",
    "    train_test_split(features_prostate_scaled, target_prostate, test_size = 0.2, random_state = 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajuste da Regressão Linear e cálculo de medidas de validação para o conjunto teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Conjunto Teste:  0.64\n",
      "EQM Conjunto Teste:  0.6\n",
      "\n",
      "\n",
      "Intercepto 2.47\n",
      "lcavol : 0.63\n",
      "lweigh : 0.27\n",
      "age : -0.12\n",
      "lbph : 0.05\n",
      "svi : 0.31\n",
      "lcp : -0.14\n",
      "gleason : 0.07\n",
      "pgg45 : 0.08\n"
     ]
    }
   ],
   "source": [
    "lr_prostate = LinearRegression()\n",
    "lr_prostate.fit(features_prostate_train, target_prostate_train);\n",
    "\n",
    "# Validação Conjunto Teste\n",
    "print(\"R^2 Conjunto Teste: \", round(lr_prostate.score(features_prostate_test, target_prostate_test),2))\n",
    "target_predicted = lr_prostate.predict(features_prostate_test)\n",
    "print(\"EQM Conjunto Teste: \",round(mean_squared_error(target_prostate_test, target_predicted),2))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Intercepto\", round(lr_prostate.intercept_,2))\n",
    "for i in range(len(lr_prostate.coef_)):\n",
    "    print(prostate_data.columns[i+1],\":\", round(lr_prostate.coef_[i],2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir dos valores apresentados acima, nota-se que as *features lcavol, lweigh, lbph, svi, gleason* e *pgg45*, por possuírem valores positivos dos coeficientes, contribuem de maneira positiva para o valor da variável resposta *lpsa*. Ou seja, o aumento do valor dessas variáveis provoca também um aumento no valor da resposta. Vale ressaltar que esse aumento provocado pelas variáveis *lbph, gleason* e *pgg45* é pequeno devido ao pequeno valor do coeficiente, em contrapartida, as variáveis *lcavol, lweigh* e*svi* possuem maior contribuição, por conta do maior valor de seus coeficientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por sua vez, as variáveis *age* e *lcp* possuem contribuição negativa sobre a variável resposta *lpsa*, pois, por terem o valor do coeficiente associado a elas negativo, um aumento no valores dessas covariáveis provoca uma redução no valor da resposta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo de regressão linear ajustado obteve o valor R-quadrado de 0.64, indicando que 64% da variabilidade da variável resposta está sendo explicada pelo modelo linear ajustado. Já o valor do erro quadrático médio, que deve sempre ser minimizado, para o modelo construído, foi obtido o valor de 0.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>x43</th>\n",
       "      <th>x44</th>\n",
       "      <th>x45</th>\n",
       "      <th>x46</th>\n",
       "      <th>x47</th>\n",
       "      <th>x48</th>\n",
       "      <th>x49</th>\n",
       "      <th>x50</th>\n",
       "      <th>x51</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.110226</td>\n",
       "      <td>0</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.223008</td>\n",
       "      <td>0</td>\n",
       "      <td>0.129464</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0</td>\n",
       "      <td>0.169210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.530075</td>\n",
       "      <td>0</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0</td>\n",
       "      <td>0.289757</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.139098</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.233083</td>\n",
       "      <td>0</td>\n",
       "      <td>0.528214</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.260602</td>\n",
       "      <td>0</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029821</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0</td>\n",
       "      <td>0.155805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033835</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111607</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.169210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     x1  x2  x3        x4  x5        x6  x7  x8  x9  x10  ...  x43       x44  \\\n",
       "0     1   0   0  0.000000   1  0.178571   0   1   0    0  ...    0  0.000000   \n",
       "1     0   1   0  0.110226   0  0.178571   0   1   0    0  ...    0  0.000000   \n",
       "2     1   0   0  0.223008   0  0.129464   1   0   0    0  ...    0  0.000000   \n",
       "3     1   0   0  0.078947   0  0.062500   0   1   0    0  ...    0  0.000000   \n",
       "4     0   1   0  0.530075   0  0.053571   1   0   0    0  ...    0  0.000000   \n",
       "..   ..  ..  ..       ...  ..       ...  ..  ..  ..  ...  ...  ...       ...   \n",
       "685   1   0   0  0.139098   0  0.026786   1   0   0    0  ...    0  0.000000   \n",
       "686   1   0   0  0.233083   0  0.528214   1   0   0    0  ...    1  0.074627   \n",
       "687   1   0   0  0.260602   0  0.053571   0   1   0    0  ...    0  0.000000   \n",
       "688   1   0   0  0.357143   0  0.029821   1   0   0    0  ...    0  0.000000   \n",
       "689   1   0   0  0.033835   0  0.111607   1   0   0    0  ...    1  0.014925   \n",
       "\n",
       "     x45  x46  x47  x48    x49  x50       x51  y  \n",
       "0      0    1    0    0  0.000    0  0.000000  1  \n",
       "1      0    1    0    0  0.000    0  0.000000  1  \n",
       "2      1    1    0    0  0.050    0  0.000000  1  \n",
       "3      1    1    0    0  0.056    0  0.169210  1  \n",
       "4      1    1    0    0  0.050    0  0.289757  1  \n",
       "..   ...  ...  ...  ...    ...  ...       ... ..  \n",
       "685    1    0    0    1  0.160    0  0.000000  1  \n",
       "686    1    1    0    0  0.084    0  0.000000  0  \n",
       "687    0    0    0    1  0.080    0  0.000000  1  \n",
       "688    0    1    0    0  0.060    0  0.155805  1  \n",
       "689    0    1    0    0  0.000    0  0.169210  1  \n",
       "\n",
       "[690 rows x 52 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_data = pd.read_csv('data/card.csv', sep=\",\")\n",
    "card_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualização da variável resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'Distribuição dos dados da variável resposta (y)')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "unique, counts = np.unique(card_data[\"y\"], return_counts = True)\n",
    "unique = ''.join(str(e) for e in unique)\n",
    "plot_data = dict(zip(unique, counts))\n",
    "\n",
    "names = list(plot_data.keys())\n",
    "values = list(plot_data.values())\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize = (5, 6))\n",
    "axs.bar(names, values)\n",
    "fig.suptitle('Distribuição dos dados da variável resposta (y)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por meio do gráfico acima, é possível notar que a variável resposta, que é categórica, possui apenas 2 níveis, sendo eles 0 ou 1. Além disso, as duas categorias possuem frequências próximas, indicando que os dados estão, de certa forma, balanceados de acordo com a variável resposta. Nesse problema serão ajustados 3 modelos diferentes para avaliação das métricas, são eles: KNN (k=5), Naive Bayes e Regressão Logística."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separação entre *features* e *target*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_card = card_data.drop(columns = {\"y\"})\n",
    "target_card = card_data[\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padronização das *features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features_card_scaled = scaler.fit_transform(features_card)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando o método 5-vizinhos mais próximos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados normalizados:\n",
      "\n",
      "\n",
      "Acurácia:  [0.79710145 0.79710145 0.76811594 0.73913043 0.82608696 0.86956522\n",
      " 0.79710145 0.82608696 0.79710145 0.7826087 ] Média:  0.8\n",
      "\n",
      "\n",
      "Recall:  [0.94871795 0.84615385 0.8974359  0.78947368 0.86842105 0.86842105\n",
      " 0.86842105 0.89473684 0.84210526 0.84210526] Média:  0.8665991902834008\n",
      "\n",
      "\n",
      "Precison:  [0.75510204 0.80487805 0.74468085 0.75       0.825      0.89189189\n",
      " 0.78571429 0.80952381 0.8        0.7804878 ] Média:  0.794727873266868\n",
      "\n",
      "\n",
      "f1:  [0.84090909 0.825      0.81395349 0.76923077 0.84615385 0.88\n",
      " 0.825      0.85       0.82051282 0.81012658] Média:  0.8280886597457101\n",
      "\n",
      "\n",
      "Dados originais:\n",
      "\n",
      "\n",
      "Acurácia:  [0.76811594 0.82608696 0.8115942  0.82608696 0.92753623 0.91304348\n",
      " 0.85507246 0.85507246 0.7826087  0.85507246] Média:  0.8420289855072463\n",
      "\n",
      "\n",
      "Recall:  [0.84615385 0.84615385 0.84615385 0.84210526 0.92105263 0.86842105\n",
      " 0.92105263 0.94736842 0.78947368 0.89473684] Média:  0.8722672064777328\n",
      "\n",
      "\n",
      "Precison:  [0.76744186 0.84615385 0.825      0.84210526 0.94594595 0.97058824\n",
      " 0.83333333 0.81818182 0.81081081 0.85      ] Média:  0.8509561113342883\n",
      "\n",
      "\n",
      "f1:  [0.80487805 0.84615385 0.83544304 0.84210526 0.93333333 0.91666667\n",
      " 0.875      0.87804878 0.8        0.87179487] Média:  0.860342384834959\n"
     ]
    }
   ],
   "source": [
    "neigh_card = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh_card.fit(features_card_scaled, target_card);\n",
    "\n",
    "# Validação cruzada com método 10-fold\n",
    "print(\"Dados normalizados:\")\n",
    "score = cross_val_score(neigh_card, features_card_scaled, target_card, cv = 10, scoring = \"accuracy\")\n",
    "print(\"\\n\")\n",
    "print(\"Acurácia: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_card, features_card_scaled, target_card, cv = 10, scoring = \"recall\")\n",
    "print(\"\\n\")\n",
    "print(\"Recall: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_card, features_card_scaled, target_card, cv = 10, scoring = \"precision\")\n",
    "print(\"\\n\")\n",
    "print(\"Precison: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_card, features_card_scaled, target_card, cv = 10, scoring = \"f1\")\n",
    "print(\"\\n\")\n",
    "print(\"f1: \", score, \"Média: \", np.mean(score))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Dados originais:\")\n",
    "score = cross_val_score(neigh_card, features_card, target_card, cv = 10, scoring = \"accuracy\")\n",
    "print(\"\\n\")\n",
    "print(\"Acurácia: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_card, features_card, target_card, cv = 10, scoring = \"recall\")\n",
    "print(\"\\n\")\n",
    "print(\"Recall: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_card, features_card, target_card, cv = 10, scoring = \"precision\")\n",
    "print(\"\\n\")\n",
    "print(\"Precison: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_card, features_card, target_card, cv = 10, scoring = \"f1\")\n",
    "print(\"\\n\")\n",
    "print(\"f1: \", score, \"Média: \", np.mean(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao ajustar o modelo de 5 vizinhos mais próximos nos dados padronizados e nos dados originais, observou-se melhor resultado no modelo em que foi utilizado os dados originais. Considerando o modelo com os dados originais, foram obtidas as seguintes métricas de avaliação do modelo:\n",
    "\n",
    "* acurácia média de 0.84;\n",
    "* sensibilidade média de 0.87\n",
    "* precisão média de 0.85\n",
    "* f1 médio de 0.86"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando o método Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia:  [0.66666667 0.73913043 0.69565217 0.66666667 0.65217391 0.69565217\n",
      " 0.73913043 0.68115942 0.68115942 0.65217391] Média:  0.6869565217391305\n",
      "Recall:  [0.97435897 1.         1.         0.86842105 0.97368421 0.94736842\n",
      " 1.         0.89473684 0.94736842 0.97368421] Média:  0.9579622132253711\n",
      "Precison:  [0.63333333 0.68421053 0.65       0.64705882 0.61666667 0.65454545\n",
      " 0.67857143 0.65384615 0.64285714 0.61666667] Média:  0.6477756196332048\n",
      "f1:  [0.76767677 0.8125     0.78787879 0.74157303 0.75510204 0.77419355\n",
      " 0.80851064 0.75555556 0.76595745 0.75510204] Média:  0.7724049859945109\n"
     ]
    }
   ],
   "source": [
    "gaussian_nb_card = GaussianNB()\n",
    "gaussian_nb_card.fit(features_card, target_card);\n",
    "\n",
    "# Validação cruzada com método 10-fold\n",
    "score = cross_val_score(gaussian_nb_card, features_card, target_card, cv = 10, scoring = \"accuracy\")\n",
    "print(\"Acurácia: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(gaussian_nb_card, features_card, target_card, cv = 10, scoring = \"recall\")\n",
    "print(\"Recall: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(gaussian_nb_card, features_card, target_card, cv = 10, scoring = \"precision\")\n",
    "print(\"Precison: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(gaussian_nb_card, features_card, target_card, cv = 10, scoring = \"f1\")\n",
    "print(\"f1: \", score, \"Média: \", np.mean(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao ajustar o modelo naive bayes nos dados originais, foram obtidas as seguintes métricas de avaliação do modelo:\n",
    "\n",
    "* acurácia média de 0.69;\n",
    "* sensibilidade média de 0.96\n",
    "* precisão média de 0.64 \n",
    "* f1 médio de 0.77"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando os resultados do modelo KNN e Naive Bayes, observou-se que o primeiro possui métricas de avaliação melhores, por possuir valores maiores dessas medidas, exceto quando se trata da sensibilidade. Nesse caso, como o modelo naive bayes possui alta sensibilidade ele é bom para identificar instâncias positiva quanto a concessão quando ela é realmente positiva. No entanto, nesse caso a precisão do modelo não é tão boa, indicando que ao classificar uma instância como positiva existe uma proporção considerável delas que na realidade é negativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando o método de Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia:  [0.76811594 0.86956522 0.85507246 0.79710145 0.86956522 0.91304348\n",
      " 0.88405797 0.86956522 0.85507246 0.88405797] Média:  0.8565217391304347\n",
      "Recall:  [0.79487179 0.87179487 0.8974359  0.73684211 0.81578947 0.86842105\n",
      " 0.86842105 0.92105263 0.78947368 0.89473684] Média:  0.8458839406207828\n",
      "Precison:  [0.79487179 0.89473684 0.85365854 0.875      0.93939394 0.97058824\n",
      " 0.91666667 0.85365854 0.9375     0.89473684] Média:  0.8930811393607778\n",
      "f1:  [0.79487179 0.88311688 0.875      0.8        0.87323944 0.91666667\n",
      " 0.89189189 0.88607595 0.85714286 0.89473684] Média:  0.8672742321782165\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_card = LogisticRegression()\n",
    "logistic_regression_card.fit(features_card_scaled,target_card)\n",
    "\n",
    "score = cross_val_score(logistic_regression_card, features_card_scaled, target_card, cv = 10, scoring = \"accuracy\")\n",
    "print(\"Acurácia: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(logistic_regression_card, features_card_scaled, target_card, cv = 10, scoring = \"recall\")\n",
    "print(\"Recall: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(logistic_regression_card, features_card_scaled, target_card, cv = 10, scoring = \"precision\")\n",
    "print(\"Precison: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(logistic_regression_card, features_card_scaled, target_card, cv = 10, scoring = \"f1\")\n",
    "print(\"f1: \", score, \"Média: \", np.mean(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao ajustar o modelo de regressão logística nos dados originais, foram obtidas seguintes métricas de avaliação do modelo:\n",
    "\n",
    "* acurácia média de 0.86;\n",
    "* sensibilidade média de 0.85\n",
    "* precisão média de 0.90\n",
    "* f1 médio de 0.87"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando o modelo logístico com os demais, ele possui sensibilidade inferior aos modelos KNN e Naive Bayes, no entanto, para as demais métricas, obteve medidas mais elevadas se comparadas com os demais modelos. Nesse caso, cabe ao banco avaliar qual métrica deve ser maximizada em um modelo para classificação da concessão de crédito. Uma alta sensibilidade indica que o modelo prevê bem instâncias como positiva quanto a concessão quando ela é realmente positiva. No entanto, também é interessante que a precisão do modelo seja alta, para assim evitar prejuízos ao aumentar a proporção de observações verdadeiramente positivas quando elas foram classificadas positivas. Nesse sentido, o modelo de regressão logística parece ser ideal, tendo valores altos para todas métricas de avaliação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importação e visualização do banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inst.Name</th>\n",
       "      <th>Private</th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top10perc</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F.Undergrad</th>\n",
       "      <th>P.Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room.Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S.F.Ratio</th>\n",
       "      <th>perc.alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad.Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilene Christian University</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1660</td>\n",
       "      <td>1232</td>\n",
       "      <td>721</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>2885</td>\n",
       "      <td>537</td>\n",
       "      <td>7440</td>\n",
       "      <td>3300</td>\n",
       "      <td>450</td>\n",
       "      <td>2200</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>18.1</td>\n",
       "      <td>12</td>\n",
       "      <td>7041</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelphi University</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2186</td>\n",
       "      <td>1924</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>2683</td>\n",
       "      <td>1227</td>\n",
       "      <td>12280</td>\n",
       "      <td>6450</td>\n",
       "      <td>750</td>\n",
       "      <td>1500</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16</td>\n",
       "      <td>10527</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adrian College</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1428</td>\n",
       "      <td>1097</td>\n",
       "      <td>336</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>1036</td>\n",
       "      <td>99</td>\n",
       "      <td>11250</td>\n",
       "      <td>3750</td>\n",
       "      <td>400</td>\n",
       "      <td>1165</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>12.9</td>\n",
       "      <td>30</td>\n",
       "      <td>8735</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agnes Scott College</td>\n",
       "      <td>Yes</td>\n",
       "      <td>417</td>\n",
       "      <td>349</td>\n",
       "      <td>137</td>\n",
       "      <td>60</td>\n",
       "      <td>89</td>\n",
       "      <td>510</td>\n",
       "      <td>63</td>\n",
       "      <td>12960</td>\n",
       "      <td>5450</td>\n",
       "      <td>450</td>\n",
       "      <td>875</td>\n",
       "      <td>92</td>\n",
       "      <td>97</td>\n",
       "      <td>7.7</td>\n",
       "      <td>37</td>\n",
       "      <td>19016</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alaska Pacific University</td>\n",
       "      <td>Yes</td>\n",
       "      <td>193</td>\n",
       "      <td>146</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>249</td>\n",
       "      <td>869</td>\n",
       "      <td>7560</td>\n",
       "      <td>4120</td>\n",
       "      <td>800</td>\n",
       "      <td>1500</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2</td>\n",
       "      <td>10922</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>Worcester State College</td>\n",
       "      <td>No</td>\n",
       "      <td>2197</td>\n",
       "      <td>1515</td>\n",
       "      <td>543</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>3089</td>\n",
       "      <td>2029</td>\n",
       "      <td>6797</td>\n",
       "      <td>3900</td>\n",
       "      <td>500</td>\n",
       "      <td>1200</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14</td>\n",
       "      <td>4469</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>Xavier University</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1959</td>\n",
       "      <td>1805</td>\n",
       "      <td>695</td>\n",
       "      <td>24</td>\n",
       "      <td>47</td>\n",
       "      <td>2849</td>\n",
       "      <td>1107</td>\n",
       "      <td>11520</td>\n",
       "      <td>4960</td>\n",
       "      <td>600</td>\n",
       "      <td>1250</td>\n",
       "      <td>73</td>\n",
       "      <td>75</td>\n",
       "      <td>13.3</td>\n",
       "      <td>31</td>\n",
       "      <td>9189</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>Xavier University of Louisiana</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2097</td>\n",
       "      <td>1915</td>\n",
       "      <td>695</td>\n",
       "      <td>34</td>\n",
       "      <td>61</td>\n",
       "      <td>2793</td>\n",
       "      <td>166</td>\n",
       "      <td>6900</td>\n",
       "      <td>4200</td>\n",
       "      <td>617</td>\n",
       "      <td>781</td>\n",
       "      <td>67</td>\n",
       "      <td>75</td>\n",
       "      <td>14.4</td>\n",
       "      <td>20</td>\n",
       "      <td>8323</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>Yale University</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10705</td>\n",
       "      <td>2453</td>\n",
       "      <td>1317</td>\n",
       "      <td>95</td>\n",
       "      <td>99</td>\n",
       "      <td>5217</td>\n",
       "      <td>83</td>\n",
       "      <td>19840</td>\n",
       "      <td>6510</td>\n",
       "      <td>630</td>\n",
       "      <td>2115</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>5.8</td>\n",
       "      <td>49</td>\n",
       "      <td>40386</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>York College of Pennsylvania</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2989</td>\n",
       "      <td>1855</td>\n",
       "      <td>691</td>\n",
       "      <td>28</td>\n",
       "      <td>63</td>\n",
       "      <td>2988</td>\n",
       "      <td>1726</td>\n",
       "      <td>4990</td>\n",
       "      <td>3560</td>\n",
       "      <td>500</td>\n",
       "      <td>1250</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>18.1</td>\n",
       "      <td>28</td>\n",
       "      <td>4509</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>777 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Inst.Name Private   Apps  Accept  Enroll  Top10perc  \\\n",
       "0      Abilene Christian University     Yes   1660    1232     721         23   \n",
       "1                Adelphi University     Yes   2186    1924     512         16   \n",
       "2                    Adrian College     Yes   1428    1097     336         22   \n",
       "3               Agnes Scott College     Yes    417     349     137         60   \n",
       "4         Alaska Pacific University     Yes    193     146      55         16   \n",
       "..                              ...     ...    ...     ...     ...        ...   \n",
       "772         Worcester State College      No   2197    1515     543          4   \n",
       "773               Xavier University     Yes   1959    1805     695         24   \n",
       "774  Xavier University of Louisiana     Yes   2097    1915     695         34   \n",
       "775                 Yale University     Yes  10705    2453    1317         95   \n",
       "776    York College of Pennsylvania     Yes   2989    1855     691         28   \n",
       "\n",
       "     Top25perc  F.Undergrad  P.Undergrad  Outstate  Room.Board  Books  \\\n",
       "0           52         2885          537      7440        3300    450   \n",
       "1           29         2683         1227     12280        6450    750   \n",
       "2           50         1036           99     11250        3750    400   \n",
       "3           89          510           63     12960        5450    450   \n",
       "4           44          249          869      7560        4120    800   \n",
       "..         ...          ...          ...       ...         ...    ...   \n",
       "772         26         3089         2029      6797        3900    500   \n",
       "773         47         2849         1107     11520        4960    600   \n",
       "774         61         2793          166      6900        4200    617   \n",
       "775         99         5217           83     19840        6510    630   \n",
       "776         63         2988         1726      4990        3560    500   \n",
       "\n",
       "     Personal  PhD  Terminal  S.F.Ratio  perc.alumni  Expend  Grad.Rate  \n",
       "0        2200   70        78       18.1           12    7041         60  \n",
       "1        1500   29        30       12.2           16   10527         56  \n",
       "2        1165   53        66       12.9           30    8735         54  \n",
       "3         875   92        97        7.7           37   19016         59  \n",
       "4        1500   76        72       11.9            2   10922         15  \n",
       "..        ...  ...       ...        ...          ...     ...        ...  \n",
       "772      1200   60        60       21.0           14    4469         40  \n",
       "773      1250   73        75       13.3           31    9189         83  \n",
       "774       781   67        75       14.4           20    8323         49  \n",
       "775      2115   96        96        5.8           49   40386         99  \n",
       "776      1250   75        75       18.1           28    4509         99  \n",
       "\n",
       "[777 rows x 19 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college_data = pd.read_csv(\"data/College.csv\")\n",
    "college_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi feita a troca da variável *Top10perc* pela variável *Elite*, sendo esta uma variável que assume o valor 0 para valores da variável *Top10perc* no intervalo (-1, 50] e 1 para valores no intervalo (50, 101]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "college_data[\"Elite\"] = pd.cut(college_data[\"Top10perc\"], bins = (-1,50,101), labels = False)\n",
    "college_data = college_data.drop(columns = {\"Top10perc\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi feita a troca da variável Private para valores inteiros (Yes = 1; No = 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "college_data[\"Private\"] = np.where(college_data[\"Private\"] == 'Yes', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualização da variável resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'Distribuição dos dados da variável resposta (Elite)')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "unique, counts = np.unique(college_data[\"Elite\"], return_counts = True)\n",
    "unique = ''.join(str(e) for e in unique)\n",
    "plot_data = dict(zip(unique, counts))\n",
    "\n",
    "names = list(plot_data.keys())\n",
    "values = list(plot_data.values())\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize = (5, 6))\n",
    "axs.bar(names, values)\n",
    "fig.suptitle('Distribuição dos dados da variável resposta (Elite)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o gráfico acima podemos perceber como a variável resposta apresenta classes (0, 1) com frequência nos dados desbalanceada. Isso deve ser observado nos modelos feitos a seguir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separação entre *features* e *target*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_college = college_data.drop(columns = {\"Inst.Name\", \"Elite\"})\n",
    "target_college = college_data[\"Elite\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi feita a padronização das *features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features_college_scaled = scaler.fit_transform(features_college)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos o método K-vizinhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados normalizados:\n",
      "Acurácia:  [0.93589744 0.96153846 0.97435897 0.94871795 0.94871795 0.93589744\n",
      " 0.91025641 0.8961039  0.97402597 0.93506494] Média:  0.942057942057942\n",
      "Recall:  [0.75       0.625      0.75       0.5        0.5        0.5\n",
      " 0.125      0.14285714 0.71428571 0.625     ] Média:  0.5232142857142856\n",
      "Precison:  [0.66666667 1.         1.         1.         1.         0.8\n",
      " 1.         0.33333333 1.         0.71428571] Média:  0.8514285714285714\n",
      "f1:  [0.70588235 0.76923077 0.85714286 0.66666667 0.66666667 0.61538462\n",
      " 0.22222222 0.2        0.83333333 0.66666667] Média:  0.6203196150254974\n",
      "\n",
      "\n",
      "Dados originais:\n",
      "Acurácia:  [0.91025641 0.93589744 0.96153846 0.93589744 0.94871795 0.92307692\n",
      " 0.8974359  0.90909091 0.92207792 0.94805195] Média:  0.9292041292041292\n",
      "Recall:  [0.5        0.375      0.625      0.5        0.5        0.375\n",
      " 0.125      0.14285714 0.57142857 0.625     ] Média:  0.43392857142857144\n",
      "Precison:  [0.57142857 1.         1.         0.8        1.         0.75\n",
      " 0.5        0.5        0.57142857 0.83333333] Média:  0.7526190476190476\n",
      "f1:  [0.53333333 0.54545455 0.76923077 0.61538462 0.66666667 0.5\n",
      " 0.2        0.22222222 0.57142857 0.71428571] Média:  0.5338006438006437\n"
     ]
    }
   ],
   "source": [
    "neigh_college = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh_college.fit(features_college_scaled, target_college);\n",
    "\n",
    "# Validação cruzada com método 10-fold\n",
    "print(\"Dados normalizados:\")\n",
    "score = cross_val_score(neigh_college, features_college_scaled, target_college, cv = 10, scoring = \"accuracy\")\n",
    "print(\"Acurácia: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_college, features_college_scaled, target_college, cv = 10, scoring = \"recall\")\n",
    "print(\"Recall: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_college, features_college_scaled, target_college, cv = 10, scoring = \"precision\")\n",
    "print(\"Precison: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_college, features_college_scaled, target_college, cv = 10, scoring = \"f1\")\n",
    "print(\"f1: \", score, \"Média: \", np.mean(score))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Dados originais:\")\n",
    "score = cross_val_score(neigh_college, features_college, target_college, cv = 10, scoring = \"accuracy\")\n",
    "print(\"Acurácia: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_college, features_college, target_college, cv = 10, scoring = \"recall\")\n",
    "print(\"Recall: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_college, features_college, target_college, cv = 10, scoring = \"precision\")\n",
    "print(\"Precison: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_college, features_college, target_college, cv = 10, scoring = \"f1\")\n",
    "print(\"f1: \", score, \"Média: \", np.mean(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver com os resultados acima conseguimos resultados melhores com a normalização das *features*. \n",
    "\n",
    "Podemos perceber também que a medida de acurácia pode ser enganosa já que, neste caso, temos classes bem desbalanceadas. Por isso as medidas *recall*, *precision* e *f1* são mais interessantes para a situação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia:  [0.92307692 0.97435897 0.94871795 0.91025641 0.97435897 0.94871795\n",
      " 0.93589744 0.88311688 0.94805195 0.90909091] Média:  0.9355644355644355\n",
      "Recall:  [0.875      1.         0.875      0.75       0.75       1.\n",
      " 0.625      0.42857143 0.85714286 1.        ] Média:  0.8160714285714284\n",
      "Precison:  [0.58333333 0.8        0.7        0.54545455 1.         0.66666667\n",
      " 0.71428571 0.375      0.66666667 0.53333333] Média:  0.658474025974026\n",
      "f1:  [0.7        0.88888889 0.77777778 0.63157895 0.85714286 0.8\n",
      " 0.66666667 0.4        0.75       0.69565217] Média:  0.7167707311757655\n"
     ]
    }
   ],
   "source": [
    "gaussian_nb_college = GaussianNB()\n",
    "gaussian_nb_college.fit(features_college, target_college);\n",
    "\n",
    "# Validação cruzada com método 10-fold\n",
    "score = cross_val_score(gaussian_nb_college, features_college, target_college, cv = 10, scoring = \"accuracy\")\n",
    "print(\"Acurácia: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(gaussian_nb_college, features_college, target_college, cv = 10, scoring = \"recall\")\n",
    "print(\"Recall: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(gaussian_nb_college, features_college, target_college, cv = 10, scoring = \"precision\")\n",
    "print(\"Precison: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(gaussian_nb_college, features_college, target_college, cv = 10, scoring = \"f1\")\n",
    "print(\"f1: \", score, \"Média: \", np.mean(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o *Naive Bayes Gaussiano* não precisamos normalizar as *features*.\n",
    "\n",
    "Podemos perceber com as métricas apresentadas acima que os resultados obtidos com o método de *Naive Bayes* foram melhores pela métrica *recall*. Esta métrica representa a proporção de classificações 1 corretamente identificadas pelo modelo dentre todas as verdadeiras classificações 1 nos dados, essa medida, em geral é muito importante e um incremento nela é algo significativo. Já na métrica *precision* tivemos uma piora em relação ao modelo k-vizinhos. Esta métrica representa a proporção de classificações 1 feitas pelo modelo que realmente são classificações 1 nos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "    black  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_data = pd.read_csv(\"data/Boston.csv\", sep = \";\", decimal = \",\")\n",
    "boston_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Visualização da variável resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 21.,  55.,  82., 154.,  84.,  41.,  30.,   8.,  10.,  21.]),\n",
       " array([ 5. ,  9.5, 14. , 18.5, 23. , 27.5, 32. , 36.5, 41. , 45.5, 50. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.hist(boston_data[\"medv\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir do histograma da variável resposta *medv*, observa-se que sua distribuição assemelha-se com uma normal, com valores mais frequentes no intervalo central e frequência reduzida nas caudas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Separação entre features e target e Padronização das features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação do Banco\n",
    "features_boston = boston_data.drop(columns = {\"medv\"})\n",
    "target_boston = boston_data[\"medv\"]\n",
    "# Padronização das Features\n",
    "scaler = StandardScaler()\n",
    "features_boston_scaled = scaler.fit_transform(features_boston)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Separação do conjunto de treinamento (80%) e do conjunto de teste (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_boston_train, features_boston_test, target_boston_train, target_boston_test = \\\n",
    "    train_test_split(features_boston_scaled, target_boston, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ajuste e Resultado do Primeiro Trabalho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2:  0.668759493535632\n",
      "\n",
      "\n",
      "Intercepto 22.485268239316902\n",
      "crim -0.9714942298153079\n",
      "zn 0.7015556186825159\n",
      "indus 0.2767521175609763\n",
      "chas 0.7065315219738251\n",
      "nox -1.9914304346295517\n",
      "rm 3.11571836395898\n",
      "age -0.17706020680903295\n",
      "dis -3.0457706454104887\n",
      "rad 2.2827847127887217\n",
      "tax -1.7926046757521554\n",
      "ptratio -1.9799535094590683\n",
      "black 1.1264986355572144\n",
      "lstat -3.6281493743713633\n",
      "\n",
      "\n",
      "EQM Conjunto Teste:  24.29\n",
      "Acurácia Base Teste:0.669\n"
     ]
    }
   ],
   "source": [
    "lr_boston = LinearRegression()\n",
    "modelo_lr_boston =lr_boston.fit(features_boston_train, target_boston_train);\n",
    "\n",
    "# Validação\n",
    "print(\"R^2: \", modelo_lr_boston.score(features_boston_test, target_boston_test))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Intercepto\", modelo_lr_boston.intercept_)\n",
    "for i in range(len(modelo_lr_boston.coef_)):\n",
    "    print(boston_data.columns[i], modelo_lr_boston.coef_[i])\n",
    "\n",
    "print(\"\\n\")\n",
    "    \n",
    "target_predicted = modelo_lr_boston.predict(features_boston_test)\n",
    "print(\"EQM Conjunto Teste: \",round(mean_squared_error(target_boston_test, target_predicted),2))\n",
    "\n",
    "print(\"Acurácia Base Teste:{:.3f}\".format(modelo_lr_boston.score(features_boston_test,target_boston_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ajuste Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia Base Teste:0.869\n",
      "Escore Variância Explicada:0.87\n",
      "MAE: 2.30\n",
      "R^2: 0.87\n",
      "EQM Conjunto Teste:  9.58\n"
     ]
    }
   ],
   "source": [
    "decisiontree = DecisionTreeRegressor(random_state=0)\n",
    "arv_dec_boston = decisiontree.fit(features_boston_train, target_boston_train)\n",
    "\n",
    "print(\"Acurácia Base Teste:{:.3f}\".format(decisiontree.score(features_boston_test,target_boston_test)))\n",
    "\n",
    "pred_arv_dec_boston = arv_dec_boston.predict(features_boston_test)\n",
    "\n",
    "explained_variance = explained_variance_score(target_boston_test, pred_arv_dec_boston)\n",
    "print('Escore Variância Explicada:{0:0.2f}'.format(explained_variance))\n",
    "\n",
    "mae= mean_absolute_error(target_boston_test, pred_arv_dec_boston)\n",
    "print('MAE: {0:0.2f}'.format(mae))\n",
    "\n",
    "r2score = r2_score(target_boston_test, pred_arv_dec_boston)\n",
    "print('R^2: {0:0.2f}'.format(r2score))\n",
    "\n",
    "print(\"EQM Conjunto Teste: \",round(mean_squared_error(target_boston_test, pred_arv_dec_boston),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ajuste Floresta Aleatória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Laura\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py:157: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int)\n",
      "C:\\Users\\Laura\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py:157: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia Base Teste:0.859\n",
      "Escore Variância Explicada:0.86\n",
      "MAE: 2.27\n",
      "R^2: 0.86\n",
      "EQM Conjunto Teste:  10.35\n"
     ]
    }
   ],
   "source": [
    "randomforest = RandomForestRegressor(random_state=0, n_jobs=-1)\n",
    "rand_for_boston = randomforest.fit(features_boston_train, target_boston_train)\n",
    "\n",
    "print(\"Acurácia Base Teste:{:.3f}\".format(rand_for_boston.score(features_boston_test,target_boston_test)))\n",
    "\n",
    "pred_rand_for_boston = rand_for_boston.predict(features_boston_test)\n",
    "\n",
    "explained_variance = explained_variance_score(target_boston_test, pred_rand_for_boston)\n",
    "print('Escore Variância Explicada:{0:0.2f}'.format(explained_variance))\n",
    "\n",
    "mae= mean_absolute_error(target_boston_test, pred_rand_for_boston)\n",
    "print('MAE: {0:0.2f}'.format(mae))\n",
    "\n",
    "r2score = r2_score(target_boston_test,pred_rand_for_boston)\n",
    "print('R^2: {0:0.2f}'.format(r2score))\n",
    "\n",
    "print(\"EQM Conjunto Teste: \",round(mean_squared_error(target_boston_test, pred_rand_for_boston),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ajuste SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia Base Teste:0.606\n",
      "Escore Variância Explicada:0.63\n",
      "MAE: 3.10\n",
      "R^2: 0.61\n",
      "EQM Conjunto Teste:  28.9\n"
     ]
    }
   ],
   "source": [
    "svm = SVR(kernel=\"linear\")\n",
    "svm_boston = svm.fit(features_boston_train, target_boston_train)\n",
    "\n",
    "print(\"Acurácia Base Teste:{:.3f}\".format(svm_boston.score(features_boston_test,target_boston_test)))\n",
    "\n",
    "pred_svm_boston = svm_boston.predict(features_boston_test)\n",
    "\n",
    "explained_variance = explained_variance_score(target_boston_test, pred_svm_boston)\n",
    "print('Escore Variância Explicada:{0:0.2f}'.format(explained_variance))\n",
    "\n",
    "mae= mean_absolute_error(target_boston_test, pred_svm_boston)\n",
    "print('MAE: {0:0.2f}'.format(mae))\n",
    "\n",
    "r2score = r2_score(target_boston_test,pred_svm_boston)\n",
    "print('R^2: {0:0.2f}'.format(r2score))\n",
    "\n",
    "print(\"EQM Conjunto Teste: \",round(mean_squared_error(target_boston_test,pred_svm_boston),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Comparação e Análise dos Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota-se que, os modelos ajustados via árvore de decisão e floresta aleatória obtiveram melhor valores de acurácia no banco de teste se comparadso com os valores obtidos na regressão linear feito anteriormente e no SVM para regressão aplicado agora. Comparando as métricas calculadas para os dois melhores modelos (árvore de decisão e a floresta aleatória), é possível observar que eles possuem valores muito próximos, porém, além da árvore possuir uma acurácia um pouco mais alta e um erro quadrático médio menor, ela possui como vantagem a sua interpretabilidade, portanto vai ser usada como referência de melhor modelo.\n",
    "\n",
    "Abaixo, tem-se o gráfico com a importância de cada uma das covariáveis para a contrução desse modelo. A variável com maior importância é *rm*, que destaca-se muito em relação as demais, seguidas das covariáveis *lstat* e *dis*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = arv_dec_boston.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "names = [boston_data.columns.tolist()[i] for i in indices]\n",
    "plt.figure()\n",
    "plt.title(\"Importância das Variáveis\")\n",
    "plt.bar(range(features_boston_train.shape[1]),\n",
    "importances[indices])\n",
    "plt.xticks(range(features_boston_train.shape[1]), names,rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDADE</th>\n",
       "      <th>TP_SEXO</th>\n",
       "      <th>ST_CONCLUSAO</th>\n",
       "      <th>IN_TP_ENSINO</th>\n",
       "      <th>IN_CERTIFICADO</th>\n",
       "      <th>TP_ESTADO_CIVIL</th>\n",
       "      <th>TP_LINGUA</th>\n",
       "      <th>Q01</th>\n",
       "      <th>Q02</th>\n",
       "      <th>Q03</th>\n",
       "      <th>...</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q26</th>\n",
       "      <th>Q27</th>\n",
       "      <th>Q28</th>\n",
       "      <th>Q29</th>\n",
       "      <th>Q30</th>\n",
       "      <th>Q31</th>\n",
       "      <th>Q32</th>\n",
       "      <th>Q33</th>\n",
       "      <th>NU_NT_MT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>342.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>411.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   IDADE TP_SEXO  ST_CONCLUSAO IN_TP_ENSINO IN_CERTIFICADO  TP_ESTADO_CIVIL  \\\n",
       "0     20       M             3                           1                0   \n",
       "1     31       F             1            1              0                1   \n",
       "2     27       F             1            1              0                1   \n",
       "3     19       F             1            1              0                0   \n",
       "4     26       F             1            1              0                0   \n",
       "\n",
       "   TP_LINGUA Q01 Q02 Q03   ...    Q25 Q26 Q27 Q28 Q29  Q30  Q31  Q32  Q33  \\\n",
       "0          1   A   C   B   ...      4   5   4   E   A    A    F    B    A   \n",
       "1          0   A   A   A   ...      5   5   5   D   A    A    B    B    A   \n",
       "2          0   A   C   C   ...      5   0   5   A   A    A    B    A    A   \n",
       "3          1   B   A   I   ...      5   4   4   B   A    A    B    A    A   \n",
       "4          1   A   I   B   ...      5   0   5   C   A    A    D    B    A   \n",
       "\n",
       "  NU_NT_MT  \n",
       "0           \n",
       "1           \n",
       "2           \n",
       "3    342.3  \n",
       "4    411.6  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enem_data_na = pd.read_csv(\"data/DadosEnemCandidatosMG.csv\", sep = \";\", decimal = \",\")\n",
    "enem_data_na.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(382179, 26)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enem_data_na.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir da visualização dos dados inicial é possível notar que esse banco de dados possui NAs, tanto em algumas covariáveis quanto na variável resposta. Como o objetivo principal do trabalho é avaliar diferentes modelos para prever a nota final dos candidatos e o banco de dados possui informações de muitos candidatos, optou-se por descartar as linhas com valores faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDADE</th>\n",
       "      <th>TP_SEXO</th>\n",
       "      <th>ST_CONCLUSAO</th>\n",
       "      <th>IN_TP_ENSINO</th>\n",
       "      <th>IN_CERTIFICADO</th>\n",
       "      <th>TP_ESTADO_CIVIL</th>\n",
       "      <th>TP_LINGUA</th>\n",
       "      <th>Q01</th>\n",
       "      <th>Q02</th>\n",
       "      <th>Q03</th>\n",
       "      <th>...</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q26</th>\n",
       "      <th>Q27</th>\n",
       "      <th>Q28</th>\n",
       "      <th>Q29</th>\n",
       "      <th>Q30</th>\n",
       "      <th>Q31</th>\n",
       "      <th>Q32</th>\n",
       "      <th>Q33</th>\n",
       "      <th>NU_NT_MT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>342.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>411.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>397.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>461.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>566.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   IDADE TP_SEXO  ST_CONCLUSAO IN_TP_ENSINO IN_CERTIFICADO  TP_ESTADO_CIVIL  \\\n",
       "3     19       F             1            1              0                0   \n",
       "4     26       F             1            1              0                0   \n",
       "6     24       F             1            1              0                0   \n",
       "7     30       F             1            1              0                1   \n",
       "8     29       M             1            1              0                1   \n",
       "\n",
       "   TP_LINGUA Q01 Q02 Q03   ...    Q25 Q26 Q27 Q28 Q29  Q30  Q31  Q32  Q33  \\\n",
       "3          1   B   A   I   ...      5   4   4   B   A    A    B    A    A   \n",
       "4          1   A   I   B   ...      5   0   5   C   A    A    D    B    A   \n",
       "6          0   B   A   A   ...      5   2   5   A   A    A    B    A    A   \n",
       "7          1   A   A   A   ...      5   0   5   C   A    A    A    A    A   \n",
       "8          1   B   B   A   ...      5   5   5   F   A    A    B    A    A   \n",
       "\n",
       "  NU_NT_MT  \n",
       "3    342.3  \n",
       "4    411.6  \n",
       "6    397.8  \n",
       "7    461.8  \n",
       "8    566.8  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_value = float(\"NaN\")\n",
    "enem_data_na.replace(\" \", nan_value, inplace=True)\n",
    "enem_data = enem_data_na.dropna()\n",
    "enem_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180638, 26)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enem_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a remoção de linhas que continham NAs, o tamanho do banco passou de 382179 obersvações para 180638. O banco continua sendo grande para o ajuste de um modelo para predição da resposta, dessa forma iremos prosseguir o estudo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Visualização da Variável Resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8452., 8695., 8701., 8988., 8796., 8379., 8296., 8711., 8228.,\n",
       "        7796., 8440., 8413., 8145., 7604., 7615., 7267., 7760., 6989.,\n",
       "        7141., 6236., 5531., 5216., 3233., 2273., 1249.,  861.,  655.,\n",
       "         448.,  314.,  206.]),\n",
       " array([   0. ,  167.9,  335.8,  503.7,  671.6,  839.5, 1007.4, 1175.3,\n",
       "        1343.2, 1511.1, 1679. , 1846.9, 2014.8, 2182.7, 2350.6, 2518.5,\n",
       "        2686.4, 2854.3, 3022.2, 3190.1, 3358. , 3525.9, 3693.8, 3861.7,\n",
       "        4029.6, 4197.5, 4365.4, 4533.3, 4701.2, 4869.1, 5037. ]),\n",
       " <BarContainer object of 30 artists>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.hist(enem_data[\"NU_NT_MT\"], bins = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analisando Covariáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IDADE               int64\n",
       "TP_SEXO            object\n",
       "ST_CONCLUSAO        int64\n",
       "IN_TP_ENSINO       object\n",
       "IN_CERTIFICADO     object\n",
       "TP_ESTADO_CIVIL     int64\n",
       "TP_LINGUA           int64\n",
       "Q01                object\n",
       "Q02                object\n",
       "Q03                object\n",
       "Q04                object\n",
       "Q05                object\n",
       "Q06                object\n",
       "Q07                object\n",
       "Q08                object\n",
       "Q24                 int64\n",
       "Q25                 int64\n",
       "Q26                 int64\n",
       "Q27                 int64\n",
       "Q28                object\n",
       "Q29                object\n",
       "Q30                object\n",
       "Q31                object\n",
       "Q32                object\n",
       "Q33                object\n",
       "NU_NT_MT           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enem_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com exceção da covariável idade, todas demais features devem ser consideradas como categóricas. A partir do comando acima nota-se que nem todas estão sendo interpretadas da maneira correta, dessa forma é necessário corrigir seus tipos para realizar o ajuste dos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
