{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Dados com Métodos de Aprendizado de Máquina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução ao Aprendizado de Máquina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daniel Rocha da Silva, Laura Kubitschek Fiorindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link para repositório no GitHub: [Repositório no GitHub](https://github.com/danielrochas/ML_Trabalho/tree/main/Trabalho%202)\n",
    "\n",
    "Descrição do trabalho: [Descrição.pdf](https://github.com/danielrochas/ML_Trabalho/blob/main/Trabalho%202/Descrição.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import explained_variance_score,mean_absolute_error,r2_score,mean_squared_error\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importação e visualização do banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prostate_data = pd.read_csv('data/prostate.data', sep=\"\\t\")\n",
    "prostate_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualização da variável resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.hist(prostate_data[\"lpsa\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir do histrograma da variável resposta *lpsa* é possível perceber que ela possui distribuição semelhante à Normal, uma vez que possui maior frequência nos valores centrais e menor frequência nas caudas a esquerda e a direita."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separação entre *features* e *target*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_prostate = prostate_data.drop(columns = {\"%\", \"lpsa\"})\n",
    "target_prostate = prostate_data[\"lpsa\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padronização das *features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features_prostate_scaled = scaler.fit_transform(features_prostate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separação do conjunto de treinamento (80%) e do conjunto de teste (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_prostate_train, features_prostate_test, target_prostate_train, target_prostate_test = \\\n",
    "    train_test_split(features_prostate_scaled, target_prostate, test_size = 0.2, random_state = 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajuste da Regressão Linear e cálculo de medidas de validação para o conjunto teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_prostate = LinearRegression()\n",
    "lr_prostate.fit(features_prostate_train, target_prostate_train);\n",
    "\n",
    "# Validação Conjunto Teste\n",
    "print(\"R^2 Conjunto Teste: \", round(lr_prostate.score(features_prostate_test, target_prostate_test),2))\n",
    "target_predicted = lr_prostate.predict(features_prostate_test)\n",
    "print(\"EQM Conjunto Teste: \",round(mean_squared_error(target_prostate_test, target_predicted),2))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Intercepto\", round(lr_prostate.intercept_,2))\n",
    "for i in range(len(lr_prostate.coef_)):\n",
    "    print(prostate_data.columns[i+1],\":\", round(lr_prostate.coef_[i],2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir dos valores apresentados acima, nota-se que as *features lcavol, lweigh, lbph, svi, gleason* e *pgg45*, por possuírem valores positivos dos coeficientes, contribuem de maneira positiva para o valor da variável resposta *lpsa*. Ou seja, o aumento do valor dessas variáveis provoca também um aumento no valor da resposta. Vale ressaltar que esse aumento provocado pelas variáveis *lbph, gleason* e *pgg45* é pequeno devido ao pequeno valor do coeficiente, em contrapartida, as variáveis *lcavol, lweigh* e*svi* possuem maior contribuição, por conta do maior valor de seus coeficientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por sua vez, as variáveis *age* e *lcp* possuem contribuição negativa sobre a variável resposta *lpsa*, pois, por terem o valor do coeficiente associado a elas negativo, um aumento no valores dessas covariáveis provoca uma redução no valor da resposta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo de regressão linear ajustado obteve o valor R-quadrado de 0.64, indicando que 64% da variabilidade da variável resposta está sendo explicada pelo modelo linear ajustado. Já o valor do erro quadrático médio, que deve sempre ser minimizado, para o modelo construído, foi obtido o valor de 0.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_data = pd.read_csv('data/card.csv', sep=\",\")\n",
    "card_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualização da variável resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "unique, counts = np.unique(card_data[\"y\"], return_counts = True)\n",
    "unique = ''.join(str(e) for e in unique)\n",
    "plot_data = dict(zip(unique, counts))\n",
    "\n",
    "names = list(plot_data.keys())\n",
    "values = list(plot_data.values())\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize = (5, 6))\n",
    "axs.bar(names, values)\n",
    "fig.suptitle('Distribuição dos dados da variável resposta (y)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por meio do gráfico acima, é possível notar que a variável resposta, que é categórica, possui apenas 2 níveis, sendo eles 0 ou 1. Além disso, as duas categorias possuem frequências próximas, indicando que os dados estão, de certa forma, balanceados de acordo com a variável resposta. Nesse problema serão ajustados 3 modelos diferentes para avaliação das métricas, são eles: KNN (k=5), Naive Bayes e Regressão Logística."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separação entre *features* e *target*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_card = card_data.drop(columns = {\"y\"})\n",
    "target_card = card_data[\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padronização das *features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features_card_scaled = scaler.fit_transform(features_card)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando o método 5-vizinhos mais próximos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh_card = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh_card.fit(features_card_scaled, target_card);\n",
    "\n",
    "# Validação cruzada com método 10-fold\n",
    "print(\"Dados normalizados:\")\n",
    "score = cross_val_score(neigh_card, features_card_scaled, target_card, cv = 10, scoring = \"accuracy\")\n",
    "print(\"\\n\")\n",
    "print(\"Acurácia: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_card, features_card_scaled, target_card, cv = 10, scoring = \"recall\")\n",
    "print(\"\\n\")\n",
    "print(\"Recall: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_card, features_card_scaled, target_card, cv = 10, scoring = \"precision\")\n",
    "print(\"\\n\")\n",
    "print(\"Precison: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_card, features_card_scaled, target_card, cv = 10, scoring = \"f1\")\n",
    "print(\"\\n\")\n",
    "print(\"f1: \", score, \"Média: \", np.mean(score))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Dados originais:\")\n",
    "score = cross_val_score(neigh_card, features_card, target_card, cv = 10, scoring = \"accuracy\")\n",
    "print(\"\\n\")\n",
    "print(\"Acurácia: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_card, features_card, target_card, cv = 10, scoring = \"recall\")\n",
    "print(\"\\n\")\n",
    "print(\"Recall: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_card, features_card, target_card, cv = 10, scoring = \"precision\")\n",
    "print(\"\\n\")\n",
    "print(\"Precison: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_card, features_card, target_card, cv = 10, scoring = \"f1\")\n",
    "print(\"\\n\")\n",
    "print(\"f1: \", score, \"Média: \", np.mean(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao ajustar o modelo de 5 vizinhos mais próximos nos dados padronizados e nos dados originais, observou-se melhor resultado no modelo em que foi utilizado os dados originais. Considerando o modelo com os dados originais, foram obtidas as seguintes métricas de avaliação do modelo:\n",
    "\n",
    "* acurácia média de 0.84;\n",
    "* sensibilidade média de 0.87\n",
    "* precisão média de 0.85\n",
    "* f1 médio de 0.86"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando o método Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_nb_card = GaussianNB()\n",
    "gaussian_nb_card.fit(features_card, target_card);\n",
    "\n",
    "# Validação cruzada com método 10-fold\n",
    "score = cross_val_score(gaussian_nb_card, features_card, target_card, cv = 10, scoring = \"accuracy\")\n",
    "print(\"Acurácia: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(gaussian_nb_card, features_card, target_card, cv = 10, scoring = \"recall\")\n",
    "print(\"Recall: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(gaussian_nb_card, features_card, target_card, cv = 10, scoring = \"precision\")\n",
    "print(\"Precison: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(gaussian_nb_card, features_card, target_card, cv = 10, scoring = \"f1\")\n",
    "print(\"f1: \", score, \"Média: \", np.mean(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao ajustar o modelo naive bayes nos dados originais, foram obtidas as seguintes métricas de avaliação do modelo:\n",
    "\n",
    "* acurácia média de 0.69;\n",
    "* sensibilidade média de 0.96\n",
    "* precisão média de 0.64 \n",
    "* f1 médio de 0.77"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando os resultados do modelo KNN e Naive Bayes, observou-se que o primeiro possui métricas de avaliação melhores, por possuir valores maiores dessas medidas, exceto quando se trata da sensibilidade. Nesse caso, como o modelo naive bayes possui alta sensibilidade ele é bom para identificar instâncias positiva quanto a concessão quando ela é realmente positiva. No entanto, nesse caso a precisão do modelo não é tão boa, indicando que ao classificar uma instância como positiva existe uma proporção considerável delas que na realidade é negativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando o método de Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_card = LogisticRegression()\n",
    "logistic_regression_card.fit(features_card_scaled,target_card)\n",
    "\n",
    "score = cross_val_score(logistic_regression_card, features_card_scaled, target_card, cv = 10, scoring = \"accuracy\")\n",
    "print(\"Acurácia: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(logistic_regression_card, features_card_scaled, target_card, cv = 10, scoring = \"recall\")\n",
    "print(\"Recall: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(logistic_regression_card, features_card_scaled, target_card, cv = 10, scoring = \"precision\")\n",
    "print(\"Precison: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(logistic_regression_card, features_card_scaled, target_card, cv = 10, scoring = \"f1\")\n",
    "print(\"f1: \", score, \"Média: \", np.mean(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao ajustar o modelo de regressão logística nos dados originais, foram obtidas seguintes métricas de avaliação do modelo:\n",
    "\n",
    "* acurácia média de 0.86;\n",
    "* sensibilidade média de 0.85\n",
    "* precisão média de 0.90\n",
    "* f1 médio de 0.87"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando o modelo logístico com os demais, ele possui sensibilidade inferior aos modelos KNN e Naive Bayes, no entanto, para as demais métricas, obteve medidas mais elevadas se comparadas com os demais modelos. Nesse caso, cabe ao banco avaliar qual métrica deve ser maximizada em um modelo para classificação da concessão de crédito. Uma alta sensibilidade indica que o modelo prevê bem instâncias como positiva quanto a concessão quando ela é realmente positiva. No entanto, também é interessante que a precisão do modelo seja alta, para assim evitar prejuízos ao aumentar a proporção de observações verdadeiramente positivas quando elas foram classificadas positivas. Nesse sentido, o modelo de regressão logística parece ser ideal, tendo valores altos para todas métricas de avaliação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importação e visualização do banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college_data = pd.read_csv(\"data/College.csv\")\n",
    "college_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi feita a troca da variável *Top10perc* pela variável *Elite*, sendo esta uma variável que assume o valor 0 para valores da variável *Top10perc* no intervalo (-1, 50] e 1 para valores no intervalo (50, 101]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college_data[\"Elite\"] = pd.cut(college_data[\"Top10perc\"], bins = (-1,50,101), labels = False)\n",
    "college_data = college_data.drop(columns = {\"Top10perc\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi feita a troca da variável Private para valores inteiros (Yes = 1; No = 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college_data[\"Private\"] = np.where(college_data[\"Private\"] == 'Yes', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualização da variável resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "unique, counts = np.unique(college_data[\"Elite\"], return_counts = True)\n",
    "unique = ''.join(str(e) for e in unique)\n",
    "plot_data = dict(zip(unique, counts))\n",
    "\n",
    "names = list(plot_data.keys())\n",
    "values = list(plot_data.values())\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize = (5, 6))\n",
    "axs.bar(names, values)\n",
    "fig.suptitle('Distribuição dos dados da variável resposta (Elite)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o gráfico acima podemos perceber como a variável resposta apresenta classes (0, 1) com frequência nos dados desbalanceada. Isso deve ser observado nos modelos feitos a seguir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separação entre *features* e *target*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_college = college_data.drop(columns = {\"Inst.Name\", \"Elite\"})\n",
    "target_college = college_data[\"Elite\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi feita a padronização das *features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features_college_scaled = scaler.fit_transform(features_college)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos o método K-vizinhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh_college = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh_college.fit(features_college_scaled, target_college);\n",
    "\n",
    "# Validação cruzada com método 10-fold\n",
    "print(\"Dados normalizados:\")\n",
    "score = cross_val_score(neigh_college, features_college_scaled, target_college, cv = 10, scoring = \"accuracy\")\n",
    "print(\"Acurácia: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_college, features_college_scaled, target_college, cv = 10, scoring = \"recall\")\n",
    "print(\"Recall: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_college, features_college_scaled, target_college, cv = 10, scoring = \"precision\")\n",
    "print(\"Precison: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_college, features_college_scaled, target_college, cv = 10, scoring = \"f1\")\n",
    "print(\"f1: \", score, \"Média: \", np.mean(score))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Dados originais:\")\n",
    "score = cross_val_score(neigh_college, features_college, target_college, cv = 10, scoring = \"accuracy\")\n",
    "print(\"Acurácia: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_college, features_college, target_college, cv = 10, scoring = \"recall\")\n",
    "print(\"Recall: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_college, features_college, target_college, cv = 10, scoring = \"precision\")\n",
    "print(\"Precison: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(neigh_college, features_college, target_college, cv = 10, scoring = \"f1\")\n",
    "print(\"f1: \", score, \"Média: \", np.mean(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver com os resultados acima conseguimos resultados melhores com a normalização das *features*. \n",
    "\n",
    "Podemos perceber também que a medida de acurácia pode ser enganosa já que, neste caso, temos classes bem desbalanceadas. Por isso as medidas *recall*, *precision* e *f1* são mais interessantes para a situação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_nb_college = GaussianNB()\n",
    "gaussian_nb_college.fit(features_college, target_college);\n",
    "\n",
    "# Validação cruzada com método 10-fold\n",
    "score = cross_val_score(gaussian_nb_college, features_college, target_college, cv = 10, scoring = \"accuracy\")\n",
    "print(\"Acurácia: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(gaussian_nb_college, features_college, target_college, cv = 10, scoring = \"recall\")\n",
    "print(\"Recall: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(gaussian_nb_college, features_college, target_college, cv = 10, scoring = \"precision\")\n",
    "print(\"Precison: \", score, \"Média: \", np.mean(score))\n",
    "score = cross_val_score(gaussian_nb_college, features_college, target_college, cv = 10, scoring = \"f1\")\n",
    "print(\"f1: \", score, \"Média: \", np.mean(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o *Naive Bayes Gaussiano* não precisamos normalizar as *features*.\n",
    "\n",
    "Podemos perceber com as métricas apresentadas acima que os resultados obtidos com o método de *Naive Bayes* foram melhores pela métrica *recall*. Esta métrica representa a proporção de classificações 1 corretamente identificadas pelo modelo dentre todas as verdadeiras classificações 1 nos dados, essa medida, em geral é muito importante e um incremento nela é algo significativo. Já na métrica *precision* tivemos uma piora em relação ao modelo k-vizinhos. Esta métrica representa a proporção de classificações 1 feitas pelo modelo que realmente são classificações 1 nos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_data = pd.read_csv(\"data/Boston.csv\", sep = \";\", decimal = \",\")\n",
    "boston_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Visualização da variável resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.hist(boston_data[\"medv\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir do histograma da variável resposta *medv*, observa-se que sua distribuição assemelha-se com uma normal, com valores mais frequentes no intervalo central e frequência reduzida nas caudas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Separação entre features e target e Padronização das features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação do Banco\n",
    "features_boston = boston_data.drop(columns = {\"medv\"})\n",
    "target_boston = boston_data[\"medv\"]\n",
    "# Padronização das Features\n",
    "scaler = StandardScaler()\n",
    "features_boston_scaled = scaler.fit_transform(features_boston)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Separação do conjunto de treinamento (80%) e do conjunto de teste (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_boston_train, features_boston_test, target_boston_train, target_boston_test = \\\n",
    "    train_test_split(features_boston_scaled, target_boston, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ajuste e Resultado do Primeiro Trabalho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_boston = LinearRegression()\n",
    "modelo_lr_boston =lr_boston.fit(features_boston_train, target_boston_train);\n",
    "\n",
    "# Validação\n",
    "print(\"R^2: \", modelo_lr_boston.score(features_boston_test, target_boston_test))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Intercepto\", modelo_lr_boston.intercept_)\n",
    "for i in range(len(modelo_lr_boston.coef_)):\n",
    "    print(boston_data.columns[i], modelo_lr_boston.coef_[i])\n",
    "\n",
    "print(\"\\n\")\n",
    "    \n",
    "target_predicted = modelo_lr_boston.predict(features_boston_test)\n",
    "print(\"EQM Conjunto Teste: \",round(mean_squared_error(target_boston_test, target_predicted),2))\n",
    "\n",
    "print(\"Acurácia Base Teste:{:.3f}\".format(modelo_lr_boston.score(features_boston_test,target_boston_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ajuste Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisiontree = DecisionTreeRegressor(random_state=0)\n",
    "arv_dec_boston = decisiontree.fit(features_boston_train, target_boston_train)\n",
    "\n",
    "print(\"Acurácia Base Teste:{:.3f}\".format(decisiontree.score(features_boston_test,target_boston_test)))\n",
    "\n",
    "pred_arv_dec_boston = arv_dec_boston.predict(features_boston_test)\n",
    "\n",
    "explained_variance = explained_variance_score(target_boston_test, pred_arv_dec_boston)\n",
    "print('Escore Variância Explicada:{0:0.2f}'.format(explained_variance))\n",
    "\n",
    "mae= mean_absolute_error(target_boston_test, pred_arv_dec_boston)\n",
    "print('MAE: {0:0.2f}'.format(mae))\n",
    "\n",
    "r2score = r2_score(target_boston_test, pred_arv_dec_boston)\n",
    "print('R^2: {0:0.2f}'.format(r2score))\n",
    "\n",
    "print(\"EQM Conjunto Teste: \",round(mean_squared_error(target_boston_test, pred_arv_dec_boston),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ajuste Floresta Aleatória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest = RandomForestRegressor(random_state=0, n_jobs=-1)\n",
    "rand_for_boston = randomforest.fit(features_boston_train, target_boston_train)\n",
    "\n",
    "print(\"Acurácia Base Teste: {:.3f}\".format(rand_for_boston.score(features_boston_test,target_boston_test)))\n",
    "\n",
    "pred_rand_for_boston = rand_for_boston.predict(features_boston_test)\n",
    "\n",
    "explained_variance = explained_variance_score(target_boston_test, pred_rand_for_boston)\n",
    "print('Escore Variância Explicada: {0:0.2f}'.format(explained_variance))\n",
    "\n",
    "mae = mean_absolute_error(target_boston_test, pred_rand_for_boston)\n",
    "print('MAE: {0:0.2f}'.format(mae))\n",
    "\n",
    "r2score = r2_score(target_boston_test,pred_rand_for_boston)\n",
    "print('R^2: {0:0.2f}'.format(r2score))\n",
    "\n",
    "print(\"EQM Conjunto Teste:\",round(mean_squared_error(target_boston_test, pred_rand_for_boston),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ajuste SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVR(kernel=\"linear\")\n",
    "svm_boston = svm.fit(features_boston_train, target_boston_train)\n",
    "\n",
    "print(\"Acurácia Base Teste:{:.3f}\".format(svm_boston.score(features_boston_test,target_boston_test)))\n",
    "\n",
    "pred_svm_boston = svm_boston.predict(features_boston_test)\n",
    "\n",
    "explained_variance = explained_variance_score(target_boston_test, pred_svm_boston)\n",
    "print('Escore Variância Explicada:{0:0.2f}'.format(explained_variance))\n",
    "\n",
    "mae= mean_absolute_error(target_boston_test, pred_svm_boston)\n",
    "print('MAE: {0:0.2f}'.format(mae))\n",
    "\n",
    "r2score = r2_score(target_boston_test,pred_svm_boston)\n",
    "print('R^2: {0:0.2f}'.format(r2score))\n",
    "\n",
    "print(\"EQM Conjunto Teste: \",round(mean_squared_error(target_boston_test,pred_svm_boston),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Comparação e Análise dos Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota-se que, os modelos ajustados via árvore de decisão e floresta aleatória obtiveram melhor valores de acurácia no banco de teste se comparadso com os valores obtidos na regressão linear feito anteriormente e no SVM para regressão aplicado agora. Comparando as métricas calculadas para os dois melhores modelos (árvore de decisão e a floresta aleatória), é possível observar que eles possuem valores muito próximos, porém, além da árvore possuir uma acurácia um pouco mais alta e um erro quadrático médio menor, ela possui como vantagem a sua interpretabilidade, portanto vai ser usada como referência de melhor modelo.\n",
    "\n",
    "Abaixo, tem-se o gráfico com a importância de cada uma das covariáveis para a contrução desse modelo. A variável com maior importância é *rm*, que destaca-se muito em relação as demais, seguidas das covariáveis *lstat* e *dis*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = arv_dec_boston.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "names = [boston_data.columns.tolist()[i] for i in indices]\n",
    "plt.figure()\n",
    "plt.title(\"Importância das Variáveis\")\n",
    "plt.bar(range(features_boston_train.shape[1]),\n",
    "importances[indices])\n",
    "plt.xticks(range(features_boston_train.shape[1]), names,rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDADE</th>\n",
       "      <th>TP_SEXO</th>\n",
       "      <th>ST_CONCLUSAO</th>\n",
       "      <th>IN_TP_ENSINO</th>\n",
       "      <th>IN_CERTIFICADO</th>\n",
       "      <th>TP_ESTADO_CIVIL</th>\n",
       "      <th>TP_LINGUA</th>\n",
       "      <th>Q01</th>\n",
       "      <th>Q02</th>\n",
       "      <th>Q03</th>\n",
       "      <th>...</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q26</th>\n",
       "      <th>Q27</th>\n",
       "      <th>Q28</th>\n",
       "      <th>Q29</th>\n",
       "      <th>Q30</th>\n",
       "      <th>Q31</th>\n",
       "      <th>Q32</th>\n",
       "      <th>Q33</th>\n",
       "      <th>NU_NT_CN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>342.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>411.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   IDADE TP_SEXO  ST_CONCLUSAO IN_TP_ENSINO IN_CERTIFICADO  TP_ESTADO_CIVIL  \\\n",
       "0     20       M             3                           1                0   \n",
       "1     31       F             1            1              0                1   \n",
       "2     27       F             1            1              0                1   \n",
       "3     19       F             1            1              0                0   \n",
       "4     26       F             1            1              0                0   \n",
       "\n",
       "   TP_LINGUA Q01 Q02 Q03  ... Q25 Q26 Q27 Q28 Q29  Q30  Q31  Q32  Q33 NU_NT_CN  \n",
       "0          1   A   C   B  ...   4   5   4   E   A    A    F    B    A           \n",
       "1          0   A   A   A  ...   5   5   5   D   A    A    B    B    A           \n",
       "2          0   A   C   C  ...   5   0   5   A   A    A    B    A    A           \n",
       "3          1   B   A   I  ...   5   4   4   B   A    A    B    A    A    342.3  \n",
       "4          1   A   I   B  ...   5   0   5   C   A    A    D    B    A    411.6  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enem_data_na = pd.read_csv(\"data/DadosEnemCandidatosMG.csv\", sep = \";\", decimal = \",\")\n",
    "enem_data_na.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(382179, 26)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enem_data_na.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir da visualização dos dados inicial é possível notar que esse banco de dados possui NAs, tanto em algumas covariáveis quanto na variável resposta. Como o objetivo principal do trabalho é avaliar diferentes modelos para prever a nota final dos candidatos e o banco de dados possui informações de muitos candidatos, optou-se por descartar as linhas com valores faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enem_data_na.replace(\" \", pd.NaT, inplace=True)\n",
    "enem_data = enem_data_na.dropna()\n",
    "enem_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180638, 26)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enem_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a remoção de linhas que continham NAs, o tamanho do banco passou de 382179 observações para 180638. O banco continua sendo grande para o ajuste de um modelo para predição da resposta, dessa forma iremos prosseguir o estudo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outro detalhe importante para realizar o ajuste dos modelos é verificar como as variáveis estão sendo interpretadas, isto é, seus tipos. A seguir foram feitas uma série de transformações a fim de que o melhor ajuste possível fosse realizado.\n",
    "\n",
    "* Alteração na codificação de algumas variáveis para aproveitar a sua característica ordinal;\n",
    "* Alteração do tipo de algumas covariáveis para melhor ajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enem_data = enem_data.replace({\"Q28\": {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6},\n",
    "                               \"Q29\": {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4},\n",
    "                               \"Q31\": {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5},\n",
    "                               \"Q32\": {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enem_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "variavel_tipo = {'TP_SEXO': 'category',\n",
    "                 'IN_TP_ENSINO': 'category',\n",
    "                 'IN_CERTIFICADO': 'category',\n",
    "                 'TP_ESTADO_CIVIL': 'category',\n",
    "                 'TP_LINGUA': 'category',\n",
    "                 'Q01': 'category',\n",
    "                 'Q02': 'category',\n",
    "                 'Q03': 'category',\n",
    "                 'Q04': 'category',\n",
    "                 'Q05': 'category',\n",
    "                 'Q06': 'category',\n",
    "                 'Q07': 'category',\n",
    "                 'Q08': 'category',\n",
    "                 'Q30': 'category',\n",
    "                 'Q33': 'category',\n",
    "                 'NU_NT_CN': 'float'}\n",
    "enem_data = enem_data.astype(variavel_tipo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_categoricas = ['TP_SEXO','IN_TP_ENSINO','IN_CERTIFICADO','TP_ESTADO_CIVIL','TP_LINGUA','Q01','Q02','Q03',\n",
    "                       'Q04','Q05','Q06','Q07','Q08','Q30','Q33']\n",
    "\n",
    "enem_data = pd.get_dummies(enem_data, prefix = colunas_categoricas,\n",
    "                           columns = colunas_categoricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDADE</th>\n",
       "      <th>ST_CONCLUSAO</th>\n",
       "      <th>Q24</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q26</th>\n",
       "      <th>Q27</th>\n",
       "      <th>Q28</th>\n",
       "      <th>Q29</th>\n",
       "      <th>Q31</th>\n",
       "      <th>Q32</th>\n",
       "      <th>...</th>\n",
       "      <th>Q30_E</th>\n",
       "      <th>Q30_F</th>\n",
       "      <th>Q30_G</th>\n",
       "      <th>Q30_H</th>\n",
       "      <th>Q33_A</th>\n",
       "      <th>Q33_B</th>\n",
       "      <th>Q33_E</th>\n",
       "      <th>Q33_F</th>\n",
       "      <th>Q33_G</th>\n",
       "      <th>Q33_H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382078</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382094</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382096</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382106</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382140</th>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180638 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        IDADE  ST_CONCLUSAO  Q24  Q25  Q26  Q27  Q28  Q29  Q31  Q32  ...  \\\n",
       "3          19             1    4    5    4    4    1    0    1    0  ...   \n",
       "4          26             1    5    5    0    5    2    0    3    1  ...   \n",
       "6          24             1    4    5    2    5    0    0    1    0  ...   \n",
       "7          30             1    3    5    0    5    2    0    0    0  ...   \n",
       "8          29             1    5    5    5    5    5    0    1    0  ...   \n",
       "...       ...           ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "382078     18             1    5    5    5    5    5    4    4    4  ...   \n",
       "382094     21             1    0    5    0    0    1    4    2    4  ...   \n",
       "382096     44             1    5    5    5    5    5    4    5    4  ...   \n",
       "382106     31             1    4    5    4    5    5    1    4    4  ...   \n",
       "382140     36             3    5    5    5    5    2    4    5    4  ...   \n",
       "\n",
       "        Q30_E  Q30_F  Q30_G  Q30_H  Q33_A  Q33_B  Q33_E  Q33_F  Q33_G  Q33_H  \n",
       "3           0      0      0      0      1      0      0      0      0      0  \n",
       "4           0      0      0      0      1      0      0      0      0      0  \n",
       "6           0      0      0      0      1      0      0      0      0      0  \n",
       "7           0      0      0      0      1      0      0      0      0      0  \n",
       "8           0      0      0      0      1      0      0      0      0      0  \n",
       "...       ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "382078      0      0      0      1      0      0      0      0      0      1  \n",
       "382094      0      1      0      0      0      0      0      0      0      1  \n",
       "382096      0      0      0      0      0      0      0      0      0      1  \n",
       "382106      0      0      0      0      0      0      0      0      0      1  \n",
       "382140      0      0      0      0      0      0      0      0      0      1  \n",
       "\n",
       "[180638 rows x 82 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enem_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Visualização da Variável Resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.4790e+03, 8.9510e+03, 8.9230e+03, 1.0652e+04, 1.2250e+04,\n",
       "        1.2980e+04, 1.3031e+04, 1.2842e+04, 1.2870e+04, 1.3270e+04,\n",
       "        1.4051e+04, 1.3661e+04, 1.2284e+04, 1.0188e+04, 7.2310e+03,\n",
       "        4.7320e+03, 3.0550e+03, 1.9410e+03, 1.2870e+03, 7.9800e+02,\n",
       "        4.9700e+02, 2.7600e+02, 1.7800e+02, 1.0300e+02, 6.0000e+01,\n",
       "        2.7000e+01, 1.4000e+01, 3.0000e+00, 2.0000e+00, 2.0000e+00]),\n",
       " array([313.4 , 335.26, 357.12, 378.98, 400.84, 422.7 , 444.56, 466.42,\n",
       "        488.28, 510.14, 532.  , 553.86, 575.72, 597.58, 619.44, 641.3 ,\n",
       "        663.16, 685.02, 706.88, 728.74, 750.6 , 772.46, 794.32, 816.18,\n",
       "        838.04, 859.9 , 881.76, 903.62, 925.48, 947.34, 969.2 ]),\n",
       " <BarContainer object of 30 artists>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.hist(enem_data[\"NU_NT_CN\"], bins = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir do histograma das notas dos candidatos, nota-se que notas maiores que 700 possuem frequência muito baixa, enquanto que o intervalo entre 400 e 600 possui uma alta frequência de ocorrência. É válido ressaltar também que a fequência na cauda da esquerda, notas entre 300 e 400, possui maior frequência se comparada com a cauda da direita a partir do valor de 700"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analisando Covariáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com exceção da covariável idade, todas demais features devem ser consideradas como categóricas. A partir do comando acima nota-se que nem todas estão sendo interpretadas da maneira correta, dessa forma é necessário corrigir seus tipos para realizar o ajuste dos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Separação entre *features* e *target*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_enem = enem_data.drop(columns = {\"NU_NT_CN\"})\n",
    "#features_enem = enem_data.TP_SEXO\n",
    "target_enem = enem_data[\"NU_NT_CN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ajuste Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.64652931 -0.78974628 -0.48600665 -0.60488856 -0.61420612 -0.57956632\n",
      " -0.63895756 -0.63669896 -0.65794195 -0.58941618]\n"
     ]
    }
   ],
   "source": [
    "decisiontree = DecisionTreeRegressor(random_state=13)\n",
    "score = cross_val_score(decisiontree, features_enem, target_enem,cv=10)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ajuste Floresta Aleatória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ajuste Regressão com Regularização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
